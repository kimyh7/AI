{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjKgoB2v_Qt2"
   },
   "source": [
    "# Transfer Learning 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKFUvuEho9Th"
   },
   "source": [
    "## 라이브러리 가져오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OGNpmn43C0O6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hQZP9vkFBUpz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4YuF5HvpM1W"
   },
   "source": [
    "## ImageNet에 대해 잘 훈련된 Feature Extractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEY_Ow5loN6q"
   },
   "source": [
    "### VGG16의 Classifier 형태 확인\n",
    "\n",
    "본 실습에서는 tf.keras.applications 에 제공되는 모델 중 2일차에 직접 작성도 하였던 VGG16을 우선 가져와 summary를 찍어보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "saYotKnJDM1W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg = tf.keras.applications.VGG16(weights=None)\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KutJaZi2DfD-"
   },
   "source": [
    "마지막 Classifier 부분의 형태를 확인할 수 있는데,\n",
    "\n",
    "> Flatten()  \n",
    "> Dense(4096)  \n",
    "> Dense(4096)  \n",
    "> Dense(1000)  \n",
    "\n",
    "으로 작성되어 있는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jn_IyOFFD-Go"
   },
   "source": [
    "### include_top 옵션\n",
    "tf.keras.applications에는 \"include_top\"이라는 옵션이 있으며, 이 옵션을 False로 두면 Classifier 부분을 날려주는 것을 확인할 수 있습니다. 아래 셀을 실행시켜 summary()를 확인해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uGgywrhkDxYm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg_notop = tf.keras.applications.VGG16(include_top=False, weights=None)\n",
    "model_vgg_notop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_nTcwkaEZLK"
   },
   "source": [
    "확인해보시면, 정확하게 Flatten()부터 제거되어 있는 것을 확인하실 수 있습니다.\n",
    "\n",
    "하지만 위에서 가져온 모델은 학습이 진행되지 않은 randomly initialized model입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cILPI8yvFBAg"
   },
   "source": [
    "### Feature Extractor (Topless Model) 가져오기\n",
    "이제 Transfer Learning 본연의 목적에 맞게 잘 학습된 모델을 활용해보기 위해 ImageNet에 대해 학습된 모델을 가져와보겠습니다.  \n",
    "이 때 들어갈 입력도 VGG16이 훈련된 224, 224에 맞춰주도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sK0Vw43Ipk9K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 10s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvFBzjT6GQKB"
   },
   "source": [
    "## Dataset 준비 - Food-5K Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8G9F7EV3cKj"
   },
   "source": [
    "실습을 위해 Dataset을 준비해보겠습니다.\n",
    "\n",
    "우선 Food-5k 데이터셋을 다운로드 받습니다.  \n",
    "Food-5k는 5000장으로 이루어진 Food or None Food의 라벨을 가진 데이터셋입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EewTyxup3vU4"
   },
   "source": [
    "- **이미지의 이름 형식은 다음과 같으며**\n",
    "> {ClassID}_{ImageID}.jpg\n",
    "  \n",
    "  \n",
    "- **ClassID와 ImageID는 아래와 같습니다.**\n",
    "> ClassID: 0 or 1; 0 means non-food and 1 means food.  \n",
    "> ImageID: ID of the image within the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfFeXehGHVtj"
   },
   "source": [
    "### Dataset 다운로드 및 디렉토리 구조 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J37sIpzibZS"
   },
   "outputs": [],
   "source": [
    "!wget https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/food-datasets/Food-5K.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5WnYnXE3fai"
   },
   "source": [
    "flow_from_directory를 활용하기 위해 디렉토리 계층구조를 재정비 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PRdaGVhqPNm"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset\n",
    "!unzip -q Food-5K.zip -d dataset\n",
    "!rm -r dataset/__MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4m14RP5ikUz"
   },
   "outputs": [],
   "source": [
    "!ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTGvKInj0lyH"
   },
   "outputs": [],
   "source": [
    "!mkdir -p dataset/training/nonfood\n",
    "!mkdir -p dataset/training/food\n",
    "!mkdir -p dataset/validation/nonfood\n",
    "!mkdir -p dataset/validation/food\n",
    "!mkdir -p dataset/evaluation/nonfood\n",
    "!mkdir -p dataset/evaluation/food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-SIKVS21LAM"
   },
   "outputs": [],
   "source": [
    "!mv dataset/training/0* dataset/training/nonfood/\n",
    "!mv dataset/training/1* dataset/training/food/\n",
    "!mv dataset/validation/0* dataset/validation/nonfood\n",
    "!mv dataset/validation/1* dataset/validation/food\n",
    "!mv dataset/evaluation/0* dataset/evaluation/nonfood\n",
    "!mv dataset/evaluation/1* dataset/evaluation/food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TytUvzur4PLk"
   },
   "source": [
    "결과적으로 데이터셋의 구조는 아래와 같아집니다.\n",
    "\n",
    "<pre>\n",
    "<b>dataset</b>\n",
    "|__ <b>training</b>\n",
    "    |______ <b>nonfood</b>: [0_0.jpg, 0_1.jpg, 0_2.jpg ....]\n",
    "    |______ <b>food</b>: [1_0.jpg, 1_1.jpg, 1_2.jpg ....]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>nonfood</b>: [0_0.jpg, 0_1.jpg, 0_2.jpg ....]\n",
    "    |______ <b>food</b>: [1_0.jpg, 1_1.jpg, 1_2.jpg ....]\n",
    "|__ <b>evaluation</b>\n",
    "    |______ <b>nonfood</b>: [0_0.jpg, 0_1.jpg, 0_2.jpg ....]\n",
    "    |______ <b>food</b>: [1_0.jpg, 1_1.jpg, 1_2.jpg ....]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3ZQrg7fLkLp"
   },
   "source": [
    "또한, 이미지를 직접 확인해보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmLG6bt8LgFk"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('dataset/training/food/1_0.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7yU1AUlLhev"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('dataset/training/nonfood/0_0.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2POK5U4HblU"
   },
   "source": [
    "### Image Generator 및 Flow를 통한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW_wPQs-4OVn"
   },
   "outputs": [],
   "source": [
    "train_dir = 'dataset/training/'\n",
    "validation_dir = 'dataset/validation/'\n",
    "\n",
    "tr_food = 'dataset/training/food/'\n",
    "tr_nfood = 'dataset/training/nonfood/'\n",
    "va_food = 'dataset/validation/food/'\n",
    "va_nfood = 'dataset/validation/nonfood/'\n",
    "\n",
    "print(len(os.listdir(tr_food)))\n",
    "print(len(os.listdir(tr_nfood)))\n",
    "print(len(os.listdir(va_food)))\n",
    "print(len(os.listdir(va_nfood)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIp_-o6kE-aH"
   },
   "source": [
    "Training Data 3000장 중 각 클래스 별 1500장,  \n",
    "Validation Data 1000장 중 각 클래스 별 500장  \n",
    "으로 구성되어 있는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aAhDNnkA-Gt"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYYPjHshAr1P"
   },
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEkrg31zA32_"
   },
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sohKlUscA5Wy"
   },
   "outputs": [],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di75Y_N0HllS"
   },
   "source": [
    "**결과적으로 food는 0으로, nonfood는 1로 지정된 것을 확인할 수 있습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16jXOhMmBP_5"
   },
   "outputs": [],
   "source": [
    "train_data_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSFY9EaTHQtr"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNTASK4KHKti"
   },
   "source": [
    "### Image Batch에 대한 Classifier 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95C9tnudJ0Ok"
   },
   "outputs": [],
   "source": [
    "sample_training_images, sample_training_labels = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I08_8Bd8HKNz"
   },
   "outputs": [],
   "source": [
    "result_batch = feature_extractor.predict(sample_training_images)\n",
    "result_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5GU4sruLHlH"
   },
   "source": [
    "각각의 이미지마다 (7, 7, 512)인 벡터가 반환되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jEWiGuFLSyo"
   },
   "source": [
    "Feature extractor layer에 있는 변수들을 학습 불가능하도록 만들면, 학습은 오직 새로운 classifier layer에만 가능하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njg9ScSaLHUV"
   },
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi-iGCVsLrGF"
   },
   "source": [
    "### Classifier를 붙이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv6kofz0LzHP"
   },
   "source": [
    "이제 `tf.keras.Sequential` 모델에 Flatten을 적용하고, 새로운 classifier layer를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JXOWkMIIFKzw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 27,560,769\n",
      "Trainable params: 27,560,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0I3d9a3M7Du"
   },
   "source": [
    "이제 완성된 모델에 샘플 이미지 Batch를 넣어보면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqrnRLtSMxYl"
   },
   "outputs": [],
   "source": [
    "predictions = model(sample_training_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpuCfXCONHSB"
   },
   "source": [
    "결과적으로 1의 출력이 나온다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU5fc2H0Mx7s"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6Wc54K3NXlf"
   },
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkJE3MPSNbQP"
   },
   "source": [
    "학습 과정을 만들기 위해 모델을 컴파일 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmS_sjXfH35Z"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x4VDBh-P4MR"
   },
   "source": [
    "5 Epoch 정도 학습을 진행시켜가며 경과를 지켜보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwIoWcyRP5iY"
   },
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfrwtTYDH3-K"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzJnjTqKPH4g"
   },
   "source": [
    "첫 번째 Epoch부터 90%를 상회하는 Validation Accuracy를 확인하실 수 있으며,  \n",
    "5 Epoch 정도 수행되었을 때 약 96% 정도로 수렴합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy4DgnWtOXKO"
   },
   "source": [
    "### 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO09LEhXH3u1"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJlDmpoTQmIh"
   },
   "source": [
    "## 학습된 모델로 Inference 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA9Da3QNQrYD"
   },
   "source": [
    "음식과 음식이 아닌 사물에 대한 이미지를 적당히 다운받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-W7wuuuBQo9R"
   },
   "outputs": [],
   "source": [
    "!wget https://media-cdn.tripadvisor.com/media/photo-s/16/5c/a9/7d/lahore-food.jpg -O food.jpg\n",
    "!wget https://www.oxfordsaudia.com/wp-content/uploads/2018/07/banner-airplane-628x439.jpg -O nonfood.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojl2JD0DReQs"
   },
   "source": [
    "이미지를 학습시킨 모델에 맞추어 rescale 후 (1, 224, 224, 3)로 변환시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAegWslKRetK"
   },
   "outputs": [],
   "source": [
    "# keras 라이브러리를 이용한 방법\n",
    "def img2input_keras(path, target_size):\n",
    "  img_show = plt.imread(path)\n",
    "  plt.imshow(img_show)\n",
    "  tmp = tf.keras.preprocessing.image.load_img(path, target_size=target_size)\n",
    "  tmp = tf.keras.preprocessing.image.img_to_array(tmp)\n",
    "  tmp = tmp/255.\n",
    "  tmp = np.expand_dims(tmp, axis=0)\n",
    "  print(tmp.shape)\n",
    "  return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bMqJLcLRjII"
   },
   "outputs": [],
   "source": [
    "food_input = img2input_keras('food.jpg', (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dWhd27qRudw"
   },
   "outputs": [],
   "source": [
    "print('food image -> ', model.predict(food_input))\n",
    "print(model.predict(food_input), 'is almost', round(model.predict(food_input)[0][0]))\n",
    "print(train_data_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcHG6a6QRjsK"
   },
   "outputs": [],
   "source": [
    "nfood_input = img2input_keras('nonfood.jpg', (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvDTuDTkRt2W"
   },
   "outputs": [],
   "source": [
    "print('nonfood image -> ', model.predict(nfood_input))\n",
    "print(model.predict(nfood_input), 'is almost', round(model.predict(nfood_input)[0][0]))\n",
    "print(train_data_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRcJnAABr22x"
   },
   "source": [
    "## Model Export 및 Load하기\n",
    "\n",
    "학습시킨 모델을 내보내었다가 다시 불러들여 그 값을 비교해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLcqg-RmsLno"
   },
   "outputs": [],
   "source": [
    "model_name = 'mymodel'\n",
    "\n",
    "export_path = \"/tmp/saved_models/\"+model_name\n",
    "model.save(export_path, save_format='tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhQ9liIUsPsi"
   },
   "source": [
    "Export된 모델을 다시 로딩할 수 있고, 이는 동일한 결과를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nI5fvkAQvbS"
   },
   "outputs": [],
   "source": [
    "reloaded = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jor83-LqI8xW"
   },
   "outputs": [],
   "source": [
    "result_batch = model.predict(sample_training_images)\n",
    "reloaded_result_batch = reloaded.predict(sample_training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnZO14taYPH6"
   },
   "outputs": [],
   "source": [
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fL_L0ij1BgQu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[wire]시각실무P8_Transfer_Learning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
