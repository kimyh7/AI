{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2_3_ML_FashionMnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7c60mMUFXpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e91eb15-ff13-469c-becc-b19f38cc047e"
      },
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Basic Datasets Question\n",
        "#\n",
        "# Create a classifier for the Fashion MNIST dataset\n",
        "# Note that the test will expect it to classify 10 classes and that the \n",
        "# input shape should be the native size of the Fashion MNIST dataset which is \n",
        "# 28x28 monochrome. Do not resize the data. YOur input layer should accept\n",
        "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
        "#\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 2 - fashion mnist\n",
        "# val_loss: 0.33\n",
        "# val_acc: 0.89\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "    train_images, test_images = train_images/255.0, test_images/255.0\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_images, train_labels, epochs = 10, verbose=1)\n",
        "    \n",
        "    #  모델평가하기\n",
        "    loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "    print(loss, accuracy)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF2-fashion-mnist.h5\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4739 - accuracy: 0.8299\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3583 - accuracy: 0.8688\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3212 - accuracy: 0.8811\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2993 - accuracy: 0.8894\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2797 - accuracy: 0.8959\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2645 - accuracy: 0.9024\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2527 - accuracy: 0.9057\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2411 - accuracy: 0.9082\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2333 - accuracy: 0.9120\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2233 - accuracy: 0.9145\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8849\n",
            "0.3461519479751587 0.8848999738693237\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}