{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHlIpxuh2RXg"
      },
      "source": [
        "# ==============================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative to its\n",
        "# difficulty. So your Category 1 question will score significantly less than\n",
        "# your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ==============================================================================\n",
        "#\n",
        "# TIME SERIES QUESTION\n",
        "#\n",
        "# Build and train a neural network to predict time indexed variables of\n",
        "# the multivariate house hold electric power consumption time series dataset.\n",
        "# Using a window of past 24 observations of the 7 variables, the model\n",
        "# should be trained to predict the next 24 observations of the 7 variables.\n",
        "#\n",
        "# ==============================================================================\n",
        "#\n",
        "# ABOUT THE DATASET\n",
        "#\n",
        "# Original Source:\n",
        "# https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption\n",
        "#\n",
        "# The original 'Individual House Hold Electric Power Consumption Dataset'\n",
        "# has Measurements of electric power consumption in one household with\n",
        "# a one-minute sampling rate over a period of almost 4 years.\n",
        "#\n",
        "# Different electrical quantities and some sub-metering values are available.\n",
        "#\n",
        "# For the purpose of the examination we have provided a subset containing\n",
        "# the data for the first 60 days in the dataset. We have also cleaned the\n",
        "# dataset beforehand to remove missing values. The dataset is provided as a\n",
        "# csv file in the project.\n",
        "#\n",
        "# The dataset has a total of 7 features ordered by time.\n",
        "# ==============================================================================\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "# Complete the code in following functions:\n",
        "# 1. windowed_dataset()\n",
        "# 2. solution_model()\n",
        "#\n",
        "# The model input and output shapes must match the following\n",
        "# specifications.\n",
        "#\n",
        "# 1. Model input_shape must be (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7),\n",
        "#    since the testing infrastructure expects a window of past N_PAST = 24\n",
        "#    observations of the 7 features to predict the next 24 observations of\n",
        "#    the same features.\n",
        "#\n",
        "# 2. Model output_shape must be (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7)\n",
        "#\n",
        "# 3. DON'T change the values of the following constants\n",
        "#    N_PAST, N_FUTURE, SHIFT in the windowed_dataset()\n",
        "#    BATCH_SIZE in solution_model() (See code for additional note on\n",
        "#    BATCH_SIZE).\n",
        "# 4. Code for normalizing the data is provided - DON't change it.\n",
        "#    Changing the normalizing code will affect your score.\n",
        "#\n",
        "# HINT: Your neural network must have a validation MAE of approximately 0.055 or\n",
        "# less on the normalized validation dataset for top marks.\n",
        "#\n",
        "# WARNING: Do not use lambda layers in your model, they are not supported\n",
        "# on the grading infrastructure.\n",
        "#\n",
        "# WARNING: If you are using the GRU layer, it is advised not to use the\n",
        "# 'recurrent_dropout' argument (you can alternatively set it to 0),\n",
        "# since it has not been implemented in the cuDNN kernel and may\n",
        "# result in much longer training times.\n",
        "import urllib\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/household_power.zip'\n",
        "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "    with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "\n",
        "# This function is used to map the un windowed time series dataset to a\n",
        "# windowed dataset so as to prepare it for training and validation.\n",
        "# A window of features are constructed by shifting the window's starting\n",
        "# position forward, one at a time (indicated by shift=1).\n",
        "# For a window of 'n_past' number of observations of all time indexed variables in\n",
        "# the dataset, the target for the window is the next 'n_future' number\n",
        "# of observations of these variables, after the end of the window.\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    # This line converts the dataset into a windowed dataset where a\n",
        "    # window consists of both the observations to be included as features\n",
        "    # and the targets.\n",
        "\n",
        "    # Don't change the shift parameter. The test windows are\n",
        "    # created with the specified shift and hence it might affect your\n",
        "    # scores. Calculate the window size so that based on\n",
        "    # the past 24 observations\n",
        "    # (observations at time steps t=1,t=2,...t=24) of the 7 variables\n",
        "    # in the dataset, you predict the next 24 observations\n",
        "    # (observations at time steps t=25,t=26....t=48) of the 7 variables\n",
        "    # of the dataset.\n",
        "\n",
        "    # Hint: Each window should include both the past observations and\n",
        "    # the future observations which are to be predicted. Calculate the\n",
        "    # window size based on n_past and n_future.\n",
        "    ds = ds.window(size=  48,\n",
        "                   shift = shift,\n",
        "                           drop_remainder = True)\n",
        "    # This line converts the windowed dataset into a tensorflow dataset.\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    \n",
        "    # Now each window in the dataset has n_past and n_future observations.\n",
        "    # This line maps each window to the form (n_past observations,\n",
        "    # n_future observations) in the format needed for training the model.\n",
        "    # Note: You can use a lambda function to map each window in the\n",
        "    # dataset to it's respective (features, targets).\n",
        "    \n",
        "    ds = ds.map(lambda w: (w[:24], w[24:]))\n",
        "    \n",
        "    return ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "# This function loads the data from csv file, normalizes the data and\n",
        "# splits the dataset into train and validation data. It also uses the\n",
        "# 'windowed_dataset' to split the data into windows of observations and\n",
        "# targets. Finally it defines, compiles and trains a neural network.\n",
        "# This function returns the trained model.\n",
        "#\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def solution_model():\n",
        "    # Downloads and extracts the dataset to the directory that\n",
        "    # contains this file.\n",
        "    download_and_extract_data()\n",
        "    # Reads the dataset from the csv.\n",
        "    df = pd.read_csv('household_power_consumption.csv', sep=',',\n",
        "                     infer_datetime_format=True, index_col='datetime', header=0)\n",
        "\n",
        "    # Number of features in the dataset. We use all features as predictors to\n",
        "    # predict all features at future time steps.\n",
        "    N_FEATURES = len(df.columns)\n",
        "    \n",
        "    # Normalizes the data\n",
        "    data = df.values\n",
        "    split_time = int(len(data) * 0.5)\n",
        "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "\n",
        "    # Splits the data into training and validation sets.\n",
        "    x_train = data[:split_time]\n",
        "    x_valid = data[split_time:]\n",
        "    \n",
        "    # DO NOT CHANGE 'BATCH_SIZE' IF YOU ARE USING STATEFUL LSTM/RNN/GRU.\n",
        "    # THE TEST WILL FAIL TO GRADE YOUR SCORE IN SUCH CASES.\n",
        "    # In other cases, it is advised not to change the batch size since it\n",
        "    # might affect your final scores. While setting it to a lower size\n",
        "    # might not do any harm, higher sizes might affect your scores.\n",
        "    BATCH_SIZE = 256  # ADVISED NOT TO CHANGE THIS\n",
        "    \n",
        "    # DO NOT CHANGE N_PAST, N_FUTURE, SHIFT. The tests will fail to run\n",
        "    # on the server.\n",
        "    \n",
        "    # Number of past time steps based on which future observations should be\n",
        "    # predicted\n",
        "    N_PAST = 24  # DO NOT CHANGE THIS\n",
        "    \n",
        "    # Number of future time steps which are to be predicted.\n",
        "    N_FUTURE = 24  # DO NOT CHANGE THIS\n",
        "    \n",
        "    # By how many positions the window slides to create a new window\n",
        "    # of observations.\n",
        "    SHIFT = 1  # DO NOT CHANGE THIS\n",
        "    # Code to create windowed train and validation datasets.\n",
        "    # Complete the code in windowed_dataset.\n",
        "    train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "    valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "    \n",
        "    # Code to define your model.\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # ADD YOUR LAYERS HERE.\n",
        "        # If you don't follow the instructions in the following comments,\n",
        "        # tests will fail to grade your code:\n",
        "        # Whatever your first layer is, the input shape will be\n",
        "        # (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7)\n",
        "        # The model must have an output shape of\n",
        "        # (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7).\n",
        "        # Make sure that there are N_FEATURES = 7 neurons in the final dense\n",
        "        # layer since the model predicts 7 features.\n",
        "        # WARNING: If you are using the GRU layer, it is advised not to use the\n",
        "        # 'recurrent_dropout' argument (you can alternatively set it to 0),\n",
        "        # since it has not been implemented in the cuDNN kernel and may\n",
        "        # result in much longer training times.\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "        tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(N_FEATURES)\n",
        "    ])\n",
        "    \n",
        "    # Code to train and compile the model\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['mae'])\n",
        "    model.fit(train_set,batch_size=256, epochs=10)\n",
        "    return model\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}