{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_예제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9JDfOjgjXOi"
      },
      "source": [
        "# CNN 예제\n",
        "\n",
        "TensorFlow 2.0을 통해 이미지 데이터를 전처리하고, CNN을 사용하는 예제를 살펴봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KticUNEmQCir"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXe76aUDuGID"
      },
      "source": [
        "## Cats vs Dogs 데이터셋 로드\n",
        "\n",
        "Cats vs Dogs 데이터셋을 로드합니다.\n",
        "\n",
        "Cats vs Dogs 데이터셋은 TFDS에서 제공하는 이미지 분류 데이터셋으로,\n",
        "\n",
        "3 color(RGB) 이미지로 강아지와 고양이 사진으로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_I2pJLrqtaA"
      },
      "source": [
        "dataset_name = 'cats_vs_dogs'\n",
        "dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mke4hFnhvu6S"
      },
      "source": [
        "## 로드한 데이터 확인\n",
        "\n",
        "예시로 몇 개의 데이터만 확인해보겠습니다.\n",
        "\n",
        "강아지, 고양이의 사진과 라벨 정보를 확인할 수 있습니다.\n",
        "\n",
        "라벨 정보는 고양이 -> 0 / 강아지 -> 1 인 것을 확인 할 수 있습니다.\n",
        "\n",
        "Cats vs Dogs Dataset의 세부적인 정보는 아래 링크에서 확인할 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/cats_vs_dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7huiYMGhquft"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = tfds.show_examples(dataset, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_gxPrVawCRA"
      },
      "source": [
        "## 데이터 전처리\n",
        "\n",
        "이 데이터로 모델을 학습시키기 위해선 각종 전처리가 필요합니다.\n",
        "\n",
        "우선 데이터의 크기가 제각각 다르므로, 동일한 크기로 Resize를 실시해야하며,\n",
        "\n",
        "0-255 사이의 pixel 값을 0-1 사이의 float 값으로 Normalize를 실시해야합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "여기서는 임의로 (224, 224) 크기로 Resize를 지정해주었습니다.\n",
        "\n",
        "preprocess 함수를 전처리 함수로 선언한 뒤, dataset.map 을 이용하여 실제로 전처리를 진행하도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQkvGl1iblF"
      },
      "source": [
        "def preprocess(features):\n",
        "  \n",
        "    img = features['image']\n",
        "    label = features['label']\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = img / 255.0\n",
        "\n",
        "    return img, label\n",
        "\n",
        "train_dataset = dataset.map(preprocess).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MdGXiyihcD"
      },
      "source": [
        "## 네트워크 정의\n",
        "\n",
        "tf.keras.models.Sequential을 이용해 CNN을 정의합니다.\n",
        "\n",
        "CNN은 구조적으로 Feature Extractor와 Classifier로 구성됩니다.\n",
        "\n",
        "Feature Extractor는 Conv2D와 MaxPooling2D 레이어로 구성되며,\n",
        "Classifier는 Flatten과 Dense 레이어로 구성됩니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "먼저, Feature Extractor를 만들기 위해, Conv2D 레이어가 필요합니다.\n",
        "\n",
        "Conv2D 레이어는 filter 갯수, kernel 사이즈, activation 함수를 argument로 받습니다.\n",
        "\n",
        "특히나 첫 레이어의 경우에는 입력되는 shape를 함께 지정해줍니다.\n",
        "\n",
        "여기서 shape는 위에서 전처리를 해주었기 때문에 (224, 224, 3) 으로 지정합니다.\n",
        "\n",
        "Conv2D 레이어 이후에는 MaxPooling2D 레이어를 추가합니다.\n",
        "\n",
        "Conv2D와 MaxPooling2D를 번갈아가며 추가하는 것으로 Feature Extractor를 구성하도록 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "2회 혹은 3회 가량 Conv2D와 MaxPooling2D를 연결한 다음, Classifier를 구성하기 위해 Flatten 레이어를 추가합니다.\n",
        "\n",
        "Flatten 레이어를 거치고 나면, 모든 parameter들이 1차원 데이터로 구성됩니다.\n",
        "\n",
        "1차원 데이터를 Dense 레이어를 통해 Fully Connected 레이어 계산을 해주도록 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "그리고 마지막에 강아지 고양이의 이진 분류를 위해서 2개의 출력 값을 갖는 Dense 레이어를 배치하도록 합니다.\n",
        "\n",
        "마지막 Dense 레이어의 activation 함수로는 softmax를 지정합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "Loss 함수를 SparseCategoricalCrossentropy로 지정하여 compile 합니다.\n",
        "\n",
        "Loss 정보가 one-hot encoding([0, 1] 혹은 [1, 0] 형태)라면 CategoricalCrossentropy를 사용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySUAYQPihMP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='RMSprop', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuVSUwxKnNDq"
      },
      "source": [
        "## 학습\n",
        "\n",
        "학습 후 결과를 확인합니다.\n",
        "\n",
        "accuracy가 90% 이상 나오도록 위의 네트워크 구조 및 학습 epoch 수를 변경하시면 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqXUViDtO0x"
      },
      "source": [
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}