{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9JDfOjgjXOi"
      },
      "source": [
        "# CNN 실습\n",
        "\n",
        "앞서 살펴본 예제를 바탕으로, 실제로 코드를 작성하는 실습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KticUNEmQCir"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXe76aUDuGID"
      },
      "source": [
        "## Rock-Paper-Scissors 데이터셋 로드\n",
        "\n",
        "Rock-Paper-Scissors 데이터셋을 로드합니다.\n",
        "\n",
        "Rock-Paper-Scissors 데이터셋은 가위, 바위, 보 게임을 하는 손 이미지를 모은 데이터셋으로, 300x300x3 크기의 이미지들로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_I2pJLrqtaA"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\n",
        "local_zip = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mke4hFnhvu6S"
      },
      "source": [
        "## 로드한 데이터 확인\n",
        "\n",
        "예시로 몇 개의 데이터만 확인해보겠습니다.\n",
        "\n",
        "현재 경로의 tmp/rps 폴더 안에 paper, rock, scissors 폴더와 이미지가 생성된 것을 확인할 수 있습니다.\n",
        "\n",
        "Rock-Scissors-Paper Dataset의 세부적인 정보는 아래 링크에서 확인할 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/rock_paper_scissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEgYnX1Y_LT5"
      },
      "source": [
        "!ls tmp/rps/paper/* | head -20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_gxPrVawCRA"
      },
      "source": [
        "## **MISSION: 데이터 전처리**\n",
        "\n",
        "##**※ 실제 시험 문제가 이와 같은 형태로 출제됩니다.**\n",
        "\n",
        "이 데이터로 모델을 학습시키기 위해선 각종 전처리가 필요합니다.\n",
        "\n",
        "TFDS 패키지를 이용한 것이 아니므로 ImageDataGenerator를 이용하여 전처리를 진행해야 합니다.\n",
        "\n",
        "##**작성할 코드**\n",
        "\n",
        "1. ImageDataGenerator를 이용하여 픽셀값 normalize를 진행하며 학습데이터를 구성하십시오.\n",
        "\n",
        "2. 구성된 학습 데이터에 flow_from_directory를 이용하여 데이터 전처리 및 batch 사이즈를 지정하십시오.\n",
        "\n",
        "3. (선택) Train/Validation Split을 진행하십시오.\n",
        "\n",
        "4. (선택) ImageDataGenerator 과정에서 Augmentation 과정을 추가하십시오.\n",
        "\n",
        "3번과 4번의 경우에는 (선택)이므로 진행하지 않아도 문제 없습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "ImageDataGenerator와 flow_from_directory에 관련한 상세한 자료는 아래 TensorFlow Document에서 확인하실 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQkvGl1iblF"
      },
      "source": [
        "TRAINING_DIR = \"tmp/rps/\"\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "    # TODO: 픽셀값 normalize와 학습데이터 구성\n",
        ")\n",
        "\n",
        "# TODO: 학습 데이터에 flow_from_directory를 이용하여 데이터 전처리 및 batch 사이즈 지정\n",
        "train_generator = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MdGXiyihcD"
      },
      "source": [
        "## **MISSION: 네트워크 정의**\n",
        "\n",
        "##**※ 실제 시험 문제가 이와 같은 형태로 출제됩니다.**\n",
        "\n",
        "위에서 변환한 데이터로 학습할 네트워크를 정의합니다.\n",
        "\n",
        "##**작성할 코드**\n",
        "\n",
        "Image Classification에 잘 동작하는 네트워크를 설계해보세요. 마지막 레이어는 그대로 둔 채, 앞 부분의 레이어들을 추가하시면 됩니다.\n",
        "\n",
        "Validation Dataset이 있다면, Validation Accuracy가 80% 이상이 되도록 설계하시면 됩니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "Conv1D, MaxPooling2D, Dense 레이어를 중심으로 구현하면 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySUAYQPihMP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # TODO: Add Layers\n",
        "    \n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuVSUwxKnNDq"
      },
      "source": [
        "## **MISSION: 네트워크 학습**\n",
        "\n",
        "##**※ 실제 시험 문제가 이와 같은 형태로 출제됩니다.**\n",
        "\n",
        "위에서 설계한 네트워크 구조를 바탕으로 compile 및 학습을 진행합니다.\n",
        "\n",
        "##**작성할 코드**\n",
        "\n",
        "설계한 네트워크에 적절한 Loss, Optimizer, Metrics을 지정하여 모델을 Compile 및 학습을 실시합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "Validation Dataset이 있다면, Validation accuracy가 80% 이상 나오도록 위의 네트워크 구조 및 학습 epoch 수를 변경하시면 좋습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqXUViDtO0x"
      },
      "source": [
        "# TODO: Compile and Training\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}