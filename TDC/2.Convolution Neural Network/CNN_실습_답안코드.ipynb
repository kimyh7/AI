{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_실습_답안코드.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9JDfOjgjXOi"
      },
      "source": [
        "# CNN 실습\n",
        "\n",
        "앞서 살펴본 예제를 바탕으로, 실제로 코드를 작성하는 실습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KticUNEmQCir"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXe76aUDuGID"
      },
      "source": [
        "## Rock-Paper-Scissors 데이터셋 로드\n",
        "\n",
        "Rock-Paper-Scissors 데이터셋을 로드합니다.\n",
        "\n",
        "Rock-Paper-Scissors 데이터셋은 가위, 바위, 보 게임을 하는 손 이미지를 모은 데이터셋으로, 300x300x3 크기의 이미지들로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_I2pJLrqtaA"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\n",
        "local_zip = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mke4hFnhvu6S"
      },
      "source": [
        "## 로드한 데이터 확인\n",
        "\n",
        "예시로 몇 개의 데이터만 확인해보겠습니다.\n",
        "\n",
        "현재 경로의 tmp/rps 폴더 안에 paper, rock, scissors 폴더와 이미지가 생성된 것을 확인할 수 있습니다.\n",
        "\n",
        "Rock-Scissors-Paper Dataset의 세부적인 정보는 아래 링크에서 확인할 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/rock_paper_scissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEgYnX1Y_LT5"
      },
      "source": [
        "!ls tmp/rps/paper/* | head -20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_gxPrVawCRA"
      },
      "source": [
        "## **MISSION: 데이터 전처리**\n",
        "## **예시 답안**\n",
        "이 데이터로 모델을 학습시키기 위해선 각종 전처리가 필요합니다.\n",
        "\n",
        "TFDS 패키지를 이용한 것이 아니므로 ImageDataGenerator를 이용하여 전처리를 진행할 것입니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "0-255 사이의 pixel 값을 0-1 사이의 float 값으로 Normalize를 실시하고,\n",
        "\n",
        "Train / Validation 의 비율을 8:2로 설정하겠습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "설정한 데이터를 flow_from_directory를 이용하여 Resize, batch_size, class_mode를 지정하겠습니다.\n",
        "\n",
        "데이터의 크기는 150x150 으로 Resize를 실시할 것이며,\n",
        "batch_size는 20,\n",
        "class_mode는 categorical로 지정하겠습니다.\n",
        "\n",
        "여기서 categorical로 지정하면 label 정보가 one-hot encoding으로 설정됩니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "ImageDataGenerator와 flow_from_directory에 관련한 상세한 자료는 아래 TensorFlow Document에서 확인하실 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQkvGl1iblF"
      },
      "source": [
        "TRAINING_DIR = \"tmp/rps/\"\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "  rescale=1. / 255,\n",
        "  validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                       target_size=(150, 150), \n",
        "                                                       batch_size=20, \n",
        "                                                       class_mode='categorical', \n",
        "                                                       subset='training',\n",
        "                                                      )\n",
        "\n",
        "validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                            target_size=(150, 150), \n",
        "                                                            batch_size=20, \n",
        "                                                            class_mode='categorical',\n",
        "                                                            subset='validation',\n",
        "                                                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MdGXiyihcD"
      },
      "source": [
        "## **MISSION: 네트워크 정의**\n",
        "## **예시 답안**\n",
        "\n",
        "먼저, Conv2D와 MaxPooling2D를 번갈아가며 추가하는 것으로 Feature Extractor를 구성하도록 합니다.\n",
        "\n",
        "2회 혹은 3회 가량 Conv2D와 MaxPooling2D를 연결한 다음, Classifier를 구성하기 위해 Flatten 레이어를 추가합니다.\n",
        "\n",
        "Flatten 레이어 이후에는 Dense 레이어를 통해 Fully Connected 레이어 계산을 해주도록 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "그리고 마지막에 Rock-Scissors-Paper의 세 개의 class 분류를 위해서 3개의 출력 값을 갖는 Dense 레이어를 배치하도록 합니다.\n",
        "\n",
        "마지막 Dense 레이어의 activation 함수로는 softmax를 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySUAYQPihMP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuVSUwxKnNDq"
      },
      "source": [
        "## **MISSION: 네트워크 학습**\n",
        "## **예시 답안**\n",
        "\n",
        "아까 flow_from_directory에서 Categorical로 class_mode를 지정하였으니 loss 함수로는 Catogoricalentropy를 사용합니다.\n",
        "\n",
        "혹시나 sparse로 지정하였다면, SparseCategoricalCrossentropy를 사용하여 compile 합니다.\n",
        "\n",
        "Optimizer의 경우에는 SGD, Adam, RMSprop, ... 등 아무거나 선택하셔도 무방합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "학습은 15 epoch을 실시하였고, 더 줄이거나 늘려도 문제 없습니다.\n",
        "\n",
        "validation accuracy가 80% 이상 나오도록 위의 네트워크 구조 및 학습 epoch 수를 변경하시면 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqXUViDtO0x"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator, epochs=15, validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgty_M-fGkQr"
      },
      "source": [
        "## 참고 사항\n",
        "\n",
        "학습 중 Train Accuracy가 100%가 되고, 점차 Train loss가 늘어나는 것으로 보아\n",
        "\n",
        "과대적합(Overfitting)이 발생함을 알 수 있습니다.\n",
        "\n",
        "이를 해결하고, 성능 향상을 위하여 ImageDataGenerator에 Augmentation을 적용할 수 있습니다.\n",
        "\n",
        "다만, Augmentation 적용 시 학습 속도가 느려질 수 있습니다.\n",
        "\n",
        "해당 코드는 아래를 참고하시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfuMoybDjFK"
      },
      "source": [
        "training_datagen = ImageDataGenerator(\n",
        "  rescale=1. / 255,\n",
        "  validation_split=0.2,\n",
        "  rotation_range=5,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                       target_size=(150, 150), \n",
        "                                                       batch_size=20, \n",
        "                                                       class_mode='categorical', \n",
        "                                                       subset='training',\n",
        "                                                      )\n",
        "\n",
        "validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                            target_size=(150, 150), \n",
        "                                                            batch_size=20, \n",
        "                                                            class_mode='categorical',\n",
        "                                                            subset='validation',\n",
        "                                                           )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}