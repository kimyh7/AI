{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2-1.ML_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSr1Fl8-U95R"
      },
      "source": [
        "# For this task you will train a classifier for Iris flowers using the Iris dataset \n",
        "# The final layer in your neural network should look like: tf.keras.layers.Dense(3, activation=tf.nn.softmax) \n",
        "# The input layer will expect data in the shape (4,) \n",
        "# We've given you some starter code for preprocessing the data \n",
        "# You'll need to implement the preprocess function for data.map \n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds \n",
        "from tensorflow.keras.optimizers import Adam \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6a-zP3be-r-",
        "outputId": "8132dd56-1edf-45b0-e235-7438959ff162"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSm_jRD4W-Ro"
      },
      "source": [
        "#data = tfds.load(\"iris\", \n",
        "#                split=tfds.Split.TRAIN.subsplit(tfds.percent[:80])) \n",
        "\n",
        "data = tfds.load(\"iris\",split='train[:80%]')\n",
        "#validation_data = tfds.load(\"iris\",split='train[80%:]')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exkcx6B1hXeg"
      },
      "source": [
        "# Dataset  전처리 - 확인\n",
        "for d in data.take(5):\n",
        "     x = d['features']\n",
        "     y = d['label']\n",
        "     y = tf.one_hot(y, 3) #3에는 dataset에서 num_classes 숫자를 찾아 넣어준다.\n",
        "     print(x)\n",
        "     print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW9qdnJqVOrH"
      },
      "source": [
        "def preprocess(features): \n",
        "    # YOUR CODE HERE \n",
        "    # Should return features and one-hot encoded labels \n",
        "    f = features['features']\n",
        "    l = features['label']\n",
        "    l = tf.one_hot(l,3)\n",
        "    return f,l \n",
        "\n",
        "def solution_model(): \n",
        "    # YOUR CODE TO TRAIN A MODEL HERE \n",
        "    train_dataset = data.map(preprocess).batch(10) \n",
        "    # valid_dataset = validation_data.map(preprocess).batch(10)\n",
        "    model = tf.keras.models.Sequential([ \n",
        "                    tf.keras.layers.Dense(512, activation= 'relu', input_shape=(4,)), \n",
        "                    tf.keras.layers.Dense(256, activation=tf.nn.relu), \n",
        "                    tf.keras.layers.Dense(64, activation=tf.nn.relu), \n",
        "                    tf.keras.layers.Dense(3, activation='softmax'), \n",
        "                    ]) \n",
        "    model.compile(optimizer='adam', \n",
        "                    loss=\"categorical_crossentropy\", \n",
        "                    metrics=['accuracy']) \n",
        "    model.fit(train_dataset, epochs=10) \n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this. \n",
        "# When you press the Submit and Test button, your saved .h5 model will \n",
        "# be sent to the testing infrastructure for scoring \n",
        "# and the score will be returned to you. \n",
        "if __name__ == '__main__': \n",
        "    model = solution_model() \n",
        "    model.save(\"mymodel.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MjnbVZNi-jg"
      },
      "source": [
        "# ModelCheckPoint: 생성하기\n",
        "# val_loss 기준으로 epoch 마다 최적의 모델을 저장하기 위하여, modelcheckpoint를 만듭니다.\n",
        "# checkpoint_path 는 모델이 저장될 파일 명을 설정합니다.\n",
        "checkpoint_path = 'my_checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(filepath = checkpoint_path,\n",
        "                             save_weightts_only = True,\n",
        "                             save_best_only = True,\n",
        "                             monitor = 'val_loss',\n",
        "                             verbose=1)\n",
        "\n",
        "## 학습시 callback에 checkpoint를 지정함\n",
        "# history = model.fit(train_dataset, validation_data=(valid_dataset), epoch = 20, callbacks=[checkpoint])\n",
        "# 학습 완료 후 load weights (ModelCheckpoint)\n",
        "# 학습이 완료된 후에는 반드시 load_wieghts 를 해줘야 하며, 그렇지 않은경우 ModelCheckpoint는 의미 없음\n",
        "# model.load_weights(checkpoint_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}