{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ì‹¤ìŠµ_7_RNN_ìˆ˜ì •.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQuwLrfneJGq",
        "colab_type": "text"
      },
      "source": [
        "# ê°ì„±ë¶„ì„ ì‹¤ìŠµ\n",
        "\n",
        "<b>í•™ìŠµ ëª©í‘œ:    \n",
        "- í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ì˜ ì „ë°˜ì ì¸ FLOWë¥¼ ì´í•´í•œë‹¤.\n",
        "- keras.Sequantial ëª¨ë“ˆì„ ì´ìš©í•´ ê°„ë‹¨í•œ ê°ì„±ë¶„ì„ ëª¨ë¸ì„ êµ¬í˜„í•´ í•™ìŠµí•˜ê³ , í•™ìŠµ ê²°ê³¼ë¥¼ ì§„ë‹¨í•œë‹¤.</b>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wg2UE1UiAne",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font color = \"red\"> \n",
        "QUIZ:   \n",
        "ìˆ«ìë§Œ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ê¸°ê³„í•™ìŠµ ëª¨ë¸ì—ê²Œ ìì—°ì–´ë¥¼ ì¸ì‹ì‹œí‚¤ëŠ” ë°©ë²•ì€? </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ695haKKAwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Cnajwnc73B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "\"\"\" í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ \"\"\"\n",
        "!pip install konlpy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHdvwAFpEcpS",
        "colab_type": "text"
      },
      "source": [
        "# # 1. ìì—°ì–´ì²˜ë¦¬ í”Œë¡œìš° ì´í•´í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RfgQ96FEjKz",
        "colab_type": "text"
      },
      "source": [
        "### Step 1. Parsing\n",
        "- konply : í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€\n",
        "- konplyì˜ Okt taggerì„ ì´ìš©í•´ í˜•íƒœì†Œ ë¶„ì„ ì‹¤í–‰\n",
        "\n",
        "<img src = \"https://github.com/seungyounglim/temporary/blob/master/image_2.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXHdDffgaggl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt=Okt()\n",
        "\n",
        "def tokenize(lines): \n",
        "  return [pos[0] for pos in okt.pos(lines)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_qXa9a0Ehzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1 = \"ì‹œê°„ ê°€ëŠ” ì¤„ ì•Œê³  ë´¤ìŠµë‹ˆë‹¤.\"\n",
        "sentence2 = \"ì•ˆë³´ë©´ í›„íšŒã… ã… ...\"\n",
        "parsed_sent1 = tokenize(sentence1)\n",
        "parsed_sent2 = tokenize(sentence2)\n",
        "print(\"ë¬¸ì¥ 1:\", parsed_sent1)\n",
        "print(\"ë¬¸ì¥ 2:\", parsed_sent2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdzQGbXMFJNu",
        "colab_type": "text"
      },
      "source": [
        "### Step 2. ëª¨ë¸ ì¸í’‹ ë§Œë“¤ê¸°\n",
        "\n",
        "<img src = \"https://github.com/seungyounglim/temporary/blob/master/image_3.PNG?raw=true\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLSdN7ROFdwN",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1) ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸°\n",
        "ìì—°ì–´ í˜•íƒœì†Œë¥¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•´ì•¼ í•¨\n",
        "- í˜•íƒœì†Œ ë¶„ì„ëœ ë‹¨ì–´ë¥¼ ì •ìˆ˜ë¡œ ë§¤í•‘í•˜ëŠ” ì‚¬ì „ ë§Œë“¤ê¸°\n",
        "- ë°°ì¹˜ ì—°ì‚°ì„ ìœ„í•´ í•„ìš”í•œ Padding([PAD])ê³¼ Out of vocabulary([OOV]) í† í°ì„ í•­ìƒ ë§¨ ì•ì— ì¶”ê°€í•´ë‘ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaZkpgi9Eh5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_dict = {}\n",
        "vocab_dict[\"[PAD]\"] = 0\n",
        "vocab_dict[\"[OOV]\"] = 1\n",
        "i = 2\n",
        "for word in parsed_sent1:\n",
        "    if word not in vocab_dict.keys():\n",
        "        vocab_dict[word] = i\n",
        "        i += 1\n",
        "for word in parsed_sent2:\n",
        "    if word not in vocab_dict.keys():\n",
        "        vocab_dict[word] = i\n",
        "        i += 1\n",
        "print(\"Vocab Dictionary Example:\")\n",
        "print(vocab_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCyqBSGYFjXx",
        "colab_type": "text"
      },
      "source": [
        "#### 2-2) vocab_dictë¥¼ ì´ìš©í•´ ìì—°ì–´ë¥¼ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°\n",
        "- ìœ„ì—ì„œ ë§Œë“  vocab_dictë¥¼ ì´ìš©í•´ íŒŒì‹±í•´ë‘” ë¬¸ì¥ì„ ëª¨ë¸ì— íƒœìš¸ ìˆ˜ ìˆëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°\n",
        "- ê¸°ë³¸ì ìœ¼ë¡œ LSTMì€ ê°€ë³€ì ì¸ ë¬¸ì¥ ê¸¸ì´ë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆì§€ë§Œ, ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ <font color=\"blue\">max_seq_len</font>ì„ ì •í•´ë‘ê³  ê¸¸ì´ë¥¼ í†µì¼í•¨    \n",
        "    - max_seq_len ë³´ë‹¤ ì§§ì€ ë¬¸ì¥ì—ëŠ” max_seq_lenì´ ë  ë•Œê¹Œì§€ [PAD]ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë¶™ì—¬ì¤Œ\n",
        "    - max_seq_len ë³´ë‹¤ ê¸´ ë¬¸ì¥ì€ max_seq_len ê°œì˜ í† í°ë§Œ ë‚¨ê¸°ê³  ìë¦„   \n",
        "       - ì•ì—ì„œë¶€í„° max_seq_len ë§Œí¼ì˜ í† í°ë§Œ ì‚¬ìš©í•œë‹¤ê±°ë‚˜\n",
        "       - ë’¤ì—ì„œë¶€í„° max_seq_len ë§Œí¼ì˜ í† í°ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜\n",
        "       - ì¤‘ê°„ë¶€ë¶„ì—ì„œ max_seq_len ë§Œí¼ë§Œ ì‚¬ìš©í•¨\n",
        "    - tensorflow.keras.preprocessing.sequenceì˜ <font color=\"blue\">pad_sequences</font> ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IfdgEZOEh3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len = 10\n",
        "\n",
        "input_id1 = [vocab_dict[word] for word in parsed_sent1]\n",
        "input_id2 = [vocab_dict[word] for word in parsed_sent2]\n",
        "\n",
        "# Padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "input_ids = [input_id1, input_id2]\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_seq_len, value = vocab_dict['[PAD]']) \n",
        "print(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGyE471IGDs1",
        "colab_type": "text"
      },
      "source": [
        "### Step3. ëª¨ë¸ ë§Œë“¤ê¸°\n",
        "\n",
        "<img src = \"https://github.com/seungyounglim/temporary/blob/master/image_4.PNG?raw=true\">\n",
        "\n",
        "- <b>tf.keras.Sequential()</b> ì„ ì‚¬ìš©í•´ ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n",
        "- Sequential()ì€ ë ˆì´ì–´ë¥¼ ì—°ì†ì ìœ¼ë¡œ ìŒ“ì•„ì„œ ëª¨ë¸ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ\n",
        "    - ì„ë² ë”© ë ˆì´ì–´ : layers.Embedding()\n",
        "    - LSTM : layers.LSTM()\n",
        "    - FC layer : layers.Dense()   \n",
        "- LSTMì„ ì‚¬ìš©í•´ ë¬¸ì¥ì„ ì¸ì½”ë”©í•˜ê³ , Fully Connected layerì„ ë‘ ì¸µ ìŒ“ì•„ ìµœì¢… outputì„ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMgZkCRJSaF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab_dict) # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = 30 # ì„ë² ë”© ì°¨ì›\n",
        "lstm_hidden_dim = 50 # LSTM hidden_size \n",
        "dense_dim = 50 #FC layer size\n",
        "batch_size = 2 # batch size\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.LSTM(lstm_hidden_dim),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiAfCsoSS7nx",
        "colab_type": "text"
      },
      "source": [
        "- <b>model.summary()</b> : ëª¨ë¸ êµ¬ì¡°, íŒŒë¼ë©”í„° ê°œìˆ˜ë¥¼ í•œ ëˆˆì— ë³´ì—¬ì¤Œ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbFyrdpWEhyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXeJUihwTHl_",
        "colab_type": "text"
      },
      "source": [
        "- <b>tf.keras.utils.plot_model()</b> : ì¸í’‹ ~ ì•„ì›ƒí’‹ê¹Œì§€ í…ì„œì˜ íë¦„ì„ ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ëƒ„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grdZX_qvSHdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, \"LSTM_sentiment_analysis.png\", show_shapes = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn2t4PeDRjfI",
        "colab_type": "text"
      },
      "source": [
        "- <b>model.predict()</b> ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ì¸í’‹ì— ëŒ€í•´ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŒ.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnagVZncO9U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.predict(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxTyxC57HY4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, s in enumerate(scores):\n",
        "    print(\"ë¬¸ì¥ {} â†’ ê¸ì •: {:.2f} / ë¶€ì •: {:.2f}\".format(i, s[0],s[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btopfDwJv2l3",
        "colab_type": "text"
      },
      "source": [
        "# # 2. LSTMìœ¼ë¡œ ê°ì„±ë¶„ì„ ëª¨ë¸ í›ˆë ¨í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YJfJrzDPG1H",
        "colab_type": "text"
      },
      "source": [
        "### Step 0. í•™ìŠµ ë°ì´í„° ì¤€ë¹„í•˜ê¸°\n",
        "<img src = \"https://github.com/seungyounglim/temporary/blob/master/image_5.PNG?raw=true\">    \n",
        "\n",
        "- ë„¤ì´ë²„ ì˜í™” ê°ì„±ë¶„ì„ ë°ì´í„°ì…‹ í™œìš©\n",
        "- í›ˆë ¨ ë°ì´í„° 150,000ê±´, í…ŒìŠ¤íŠ¸ ë°ì´í„° 50,000ê±´"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHygGkDeiyUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ \"\"\"\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUMj2VCv_Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" ë°ì´í„° ì½ì–´ì˜¤ê¸° \"\"\"\n",
        "\n",
        "with open(\"ratings_train.txt\") as f:\n",
        "    raw_train = f.readlines()\n",
        "with open(\"ratings_test.txt\") as f:\n",
        "    raw_test = f.readlines()\n",
        "raw_train = [t.split('\\t') for t in raw_train[1:]]\n",
        "raw_test = [t.split('\\t') for t in raw_test[1:]]\n",
        "\n",
        "FULL_TRAIN = []\n",
        "for line in raw_train:\n",
        "    FULL_TRAIN.append([line[0], line[1], int(line[2].strip())])\n",
        "FULL_TEST = []\n",
        "for line in raw_test:\n",
        "    FULL_TEST.append([line[0], line[1], int(line[2].strip())])\n",
        "print(\"FULL_TRAIN: {}ê°œ (ê¸ì • {}, ë¶€ì • {})\".format(len(FULL_TRAIN), sum([t[2] for t in FULL_TRAIN]), len(FULL_TRAIN)-sum([t[2] for t in FULL_TRAIN])), FULL_TRAIN[0])\n",
        "print(\"FULL_TEST : {}ê°œ (ê¸ì • {}, ë¶€ì • {})\".format(len(FULL_TEST), sum([t[2] for t in FULL_TEST]), len(FULL_TEST)-sum([t[2] for t in FULL_TEST])), FULL_TEST[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1IWVSphmZ42",
        "colab_type": "text"
      },
      "source": [
        "### label \n",
        "> 0: ë¶€ì •\n",
        "\n",
        "> 1: ê¸ì •"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7II5hOLsEzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ë°ì´í„° ì˜ˆì‹œ : id, ë¬¸ì¥, ë¼ë²¨ ìˆœì„œ\n",
        "print(FULL_TRAIN[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCyE6Ia5uopA",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://github.com/seungyounglim/temporary/blob/master/image_6.PNG?raw=true\">  \n",
        "- ì‹œê°„ ê´€ê³„ìƒ train ì¤‘ 50,000ê±´ì„ í•™ìŠµë°ì´í„°, 10,000ê±´ì„ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
        "- test ì¤‘ 10,000ê±´ë§Œ ìƒ˜í”Œë§í•˜ì—¬ ìµœì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_xG06TPI9vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "random.shuffle(FULL_TRAIN)\n",
        "random.shuffle(FULL_TEST)\n",
        "train = FULL_TRAIN[:50000]\n",
        "val = FULL_TRAIN[50000:60000]\n",
        "test = FULL_TEST[:10000]\n",
        "print(\"train     : {}ê°œ (ê¸ì • {}, ë¶€ì • {})\".format(len(train), sum([t[2] for t in train]), len(train)-sum([t[2] for t in train])), train[0])\n",
        "print(\"validation: {}ê°œ (ê¸ì • {}, ë¶€ì • {})\".format(len(val), sum([t[2] for t in val]), len(val)-sum([t[2] for t in val])), val[0])\n",
        "print(\"test      : {}ê°œ (ê¸ì • {}, ë¶€ì • {})\".format(len(test), sum([t[2] for t in test]), len(test)-sum([t[2] for t in test])), test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jykZkziwnd2",
        "colab_type": "text"
      },
      "source": [
        "## Step 1. Parsing\n",
        "- Train/ Testì˜ ë¬¸ì¥ì„ í˜•íƒœì†Œë¶„ì„ê¸°ë¡œ íŒŒì‹±í•˜ì—¬ train_sentences, test_sentencesì— ì €ì¥í•´ë‘ .\n",
        "- categorical_crossentropy lossë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì •ë‹µ ë¼ë²¨ì€ One-hot encoding í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
        "   - ë¶€ì • -> [1, 0]\n",
        "   - ê¸ì • -> [0 , 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9HFloKROOnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences = []\n",
        "val_sentences = []\n",
        "test_sentences = []\n",
        "\n",
        "# ì¶”í›„ í•™ìŠµ/ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¼ë²¨ ì •ë³´ ì €ì¥í•´ë‘ \n",
        "train_label_ids = []\n",
        "val_label_ids = []\n",
        "test_label_ids = []\n",
        "\n",
        "print(\"start tokenizing TRAIN sentences\")\n",
        "for i, line in enumerate(train):\n",
        "    tokens = tokenize(line[1])\n",
        "    train_sentences.append(tokens)\n",
        "    if line[2] == 0: # ë¶€ì •\n",
        "      train_label_ids.append([1,0])\n",
        "    else: #ê¸ì •\n",
        "      train_label_ids.append([0,1])\n",
        "\n",
        "    if (i+1) % 5000 == 0: print(\"... {}/{} done\".format(i+1, len(train)))\n",
        "\n",
        "print(\"example:\", train_sentences[-1], train_label_ids[-1], \"\\n\")\n",
        "\n",
        "print(\"start tokenizing VALIDATION sentences\")\n",
        "\n",
        "for line in val:\n",
        "    tokens = tokenize(line[1])\n",
        "    val_sentences.append(tokens)\n",
        "    if line[2] == 0: # ë¶€ì •\n",
        "      val_label_ids.append([1,0])\n",
        "    else: #ê¸ì •\n",
        "      val_label_ids.append([0,1])\n",
        "print(\"... done\\n\")\n",
        "\n",
        "print(\"start tokenizing TEST sentences\")\n",
        "for line in test:\n",
        "    tokens = tokenize(line[1])\n",
        "    test_sentences.append(tokens)\n",
        "    if line[2] == 0: # ë¶€ì •\n",
        "      test_label_ids.append([1,0])\n",
        "    else: #ê¸ì •\n",
        "      test_label_ids.append([0,1])\n",
        "\n",
        "print(\"... done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58bDXwmsH2x6",
        "colab_type": "text"
      },
      "source": [
        "##Step 2. ëª¨ë¸ ì¸í’‹ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFXWtJDWdH1E",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1) ë‹¨ì–´ì‚¬ì „ ë§Œë“¤ê¸°\n",
        "- í›ˆë ¨ ë°ì´í„° ë¬¸ì¥ì— ìˆëŠ” í˜•íƒœì†Œë¥¼ ì´ìš©í•´ êµ¬ì¶•\n",
        "- (ì¼ë°˜ì ìœ¼ë¡œëŠ” ë” ë§ì€ ì½”í¼ìŠ¤ì— ëŒ€í•´ êµ¬ì¶•ëœ ì‚¬ì „ì„ ì‚¬ìš©í•˜ì§€ë§Œ, í¸ì˜ìƒ í›ˆë ¨ì…‹ë§Œìœ¼ë¡œ ì§„í–‰)\n",
        "\n",
        "# ì‹¤ìŠµ MISSION #14\n",
        "[CODE] ë¶€ë¶„ì„ ì±„ì›Œë„£ì–´ ë‹¨ì–´ì‚¬ì „ì„ ë§Œë“¤ê³  ìƒì„±ëœ ë‹¨ì–´ì‚¬ì „ì˜ í¬ê¸°ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAfNMCpgwdww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "vocab_dict = {}\n",
        "vocab_dict[\"[PAD]\"] = 0\n",
        "vocab_dict[\"[OOV]\"] = 1\n",
        "i = 2\n",
        "for sentence in train_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in vocab_dict.keys():\n",
        "            ## [CODE] ##\n",
        "            \n",
        "            ############\n",
        "            i += 1\n",
        "print(\"Vocab Dictionary Size:\", len(vocab_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu_DabQjQYFK",
        "colab_type": "text"
      },
      "source": [
        "#### 2-2) vocab_dictë¥¼ ì´ìš©í•´ ìì—°ì–´ë¥¼ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°\n",
        "\n",
        "# ì‹¤ìŠµ MISSION #15\n",
        "> í† í°í™”ëœ ë¬¸ì¥ë“¤ (tokenized_sentences)ì„ ì¸í’‹ìœ¼ë¡œ ë°›ì•„ ë‹¤ìŒì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì‹œì˜¤\n",
        "\n",
        "* ë‹¨ì–´ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ëŠ” [OOV] ì¸ë±ìŠ¤ë¡œ ì²˜ë¦¬í•˜ê¸°   \n",
        "* ë‹¨ì–´ì‚¬ì „ì—ì„œ ë§¤í•‘ë˜ëŠ” ë‹¨ì–´ëŠ” í•´ë‹¹ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°   \n",
        "* ë¬¸ì¥ ê¸¸ì´ë¥¼ 'max_seq_len'ìœ¼ë¡œ ë§ì¶”ì–´, max_seq_lenë³´ë‹¤ ê¸´ ë¬¸ì¥ì€ ë’·ë¶€ë¶„ì„ ìë¥´ê³ , max_seq_lenë³´ë‹¤ ì§§ì€ ë¬¸ì¥ì€ ë’·ë¶€ë¶„ì— paddingí•˜ê¸° "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHI2uFCUojkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_input_ids(tokenized_sentences, max_seq_len = 50):\n",
        "  \n",
        "  num_oov = 0 # OOV ë°œìƒ ê°œìˆ˜ë¥¼ ì…ˆ\n",
        "  result_input_ids = [] # result_input_ids : ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•œ ë¬¸ì¥ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "  for sentence in tokenized_sentences :\n",
        "      \"\"\" vocab_dictë¥¼ ì‚¬ìš©í•´ ì •ìˆ˜ë¡œ ë³€í™˜ \"\"\" \n",
        "      input_ids = []\n",
        "      for token in sentence:\n",
        "          if token not in vocab_dict: \n",
        "              input_ids.append(__________________) ## a. [CODE] OOV ì²˜ë¦¬\n",
        "              num_oov += 1\n",
        "          else:\n",
        "              input_ids.append(__________________) ## b. [CODE] ë‹¨ì–´ì‚¬ì „ì—ì„œ í† í° ì°¾ì•„ì„œ ë¶™ì´ê¸°\n",
        "      \n",
        "      result_input_ids.append(input_ids)\n",
        "      \n",
        "  \"\"\" max_seq_lenì„ ë„˜ëŠ” ë¬¸ì¥ì€ ì ˆë‹¨, ëª¨ìë¥´ëŠ” ê²ƒì€ PADDING \"\"\"\n",
        "  result_input_ids = pad_sequences(result_input_ids, maxlen=____, padding='___', truncating='___', value = 0) ## c. [CODE] padding í•˜ê¸°\n",
        "\n",
        "  return result_input_ids, num_oov\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irm8oGg3ICWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_sentences ì²˜ë¦¬\n",
        "train_input_ids, num_oov = make_input_ids(train_sentences)\n",
        "\n",
        "print(\"---- TRAIN ----\")\n",
        "print(\"... # OOVs     :\", num_oov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yFz1GGuxhGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# val_sentences ì²˜ë¦¬\n",
        "val_input_ids, num_oov = make_input_ids(val_sentences)\n",
        "\n",
        "print(\"---- VALIDATION ----\")\n",
        "print(\"... # OOVs     :\", num_oov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYs0YXRjIDg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_sentences ì²˜ë¦¬\n",
        "test_input_ids, num_oov = make_input_ids(test_sentences)\n",
        "\n",
        "print(\"---- TEST ----\")\n",
        "print(\"... # OOVs     :\", num_oov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7l98rF7c-Er",
        "colab_type": "text"
      },
      "source": [
        "#### 2-3) ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ë¥¼ np.arrayë¡œ ë³€í™˜\n",
        "- TIP: tensorflow2.0ì—ì„œëŠ” numpy arrayë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ì•„ë“¤ì„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFQFHbj3AQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_ids = np.array(train_label_ids)\n",
        "val_label_ids = np.array(val_label_ids)\n",
        "test_label_ids = np.array(test_label_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhcHsul1IHxj",
        "colab_type": "text"
      },
      "source": [
        "## Step3. ëª¨ë¸ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39iPCdwGTjzk",
        "colab_type": "text"
      },
      "source": [
        "# ì‹¤ìŠµ MISSION #16\n",
        "> ì•„ë˜ ì¡°ê±´ì— ë§ëŠ” ëª¨ë¸ì„ ë§Œë“œì‹œì˜¤\n",
        " \n",
        "* embedding ì°¨ì›ì€ 150\n",
        "* LSTM hidden sizeëŠ” 100\n",
        "* Denseì˜ hidden sizeëŠ” 100, relu activation ì‚¬ìš©\n",
        "* output Dense layerì—ì„œëŠ” ê¸/ë¶€ì • 2ê°œ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ë˜ softmax ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcDr8GlZTqqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "vocab_size = len(vocab_dict) \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "            ####### MISSION ì‘ì„± ######\n",
        "\n",
        "            ###########################\n",
        "])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlpgWelVIMXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GXrD_dTdTa_",
        "colab_type": "text"
      },
      "source": [
        "## Step 4. ëª¨ë¸ í›ˆë ¨í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPp_wZ2ddaMG",
        "colab_type": "text"
      },
      "source": [
        "#### 4-1) <b>model.compile()</b>ì„ í†µí•´ loss, optimizer ì§€ì •"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nPJiGW1q92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wQWmz8Xdi89",
        "colab_type": "text"
      },
      "source": [
        "#### 4-2) model.fit()ì„ í†µí•´ ëª¨ë¸ í›ˆë ¨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6jyqi5cdjJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 5\n",
        "history = model.fit(train_input_ids, train_label_ids, epochs=num_epochs, validation_data=(val_input_ids, val_label_ids), verbose=2) \n",
        "\n",
        "test_result = model.evaluate(test_input_ids, test_label_ids, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpO7-KgJxFZI",
        "colab_type": "text"
      },
      "source": [
        "<font color='purple'>ğŸš´â€â™€ï¸<i> while training...</i></font>   \n",
        "<br>\n",
        "<u> keras RNN API í™•ì¸í•˜ê¸°</u>\n",
        "- https://www.tensorflow.org/guide/keras/rnn\n",
        "- ê¸°ë³¸ì ì¸ RNN ì´ì™¸ì— Bidirectional RNN, Multi-layer RNN êµ¬ì¡° ë“±ì„ í™œìš©í•˜ê³  ì‹¶ë‹¤ë©´ API ë¬¸ì„œë¥¼ ì°¸ê³ í•´ ë§Œë“¤ ìˆ˜ ìˆìŒ.\n",
        "- ì˜ˆ) \n",
        "  - LSTMì˜ ëª¨ë“  timestepì˜ outputì„ ë°›ì•„ì˜¤ë ¤ë©´ \n",
        "  - lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=True)ë¡œ ì„¤ì •\n",
        "  - Bidirectional-LSTMì„ ì‚¬ìš©í•˜ë ¤ë©´\n",
        "  - layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42MnPFs9O3Fr",
        "colab_type": "text"
      },
      "source": [
        "#### 4-3) í›ˆë ¨ ê²°ê³¼ ì§„ë‹¨í•˜ê¸°\n",
        "<font color=\"red\">QUIZ :   \n",
        "a. í˜„ì¬ ëª¨ë¸ì— ë¬¸ì œì ì´ ìˆë‚˜ìš”?   \n",
        "b. ë¬¸ì œê°€ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤ë©´ ì´ì— ëŒ€í•œ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•´ ë³´ì„¸ìš”. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtaGxpJa4SmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13AeKZe8JdIn",
        "colab_type": "text"
      },
      "source": [
        "## Step 5. Inference ì‹¤í–‰í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxopYLQtIkw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" í›ˆë ¨ëœ ëª¨ë¸ë¡œ ë‹¤ì‹œ ì˜ˆì¸¡í•´ë³´ê¸° \"\"\"\n",
        "\n",
        "def inference(mymodel, sentence):\n",
        "  # 1. tokenizerë¡œ ë¬¸ì¥ íŒŒì‹±\n",
        "  parsed_sent = tokenize(sentence)\n",
        "  input_id = []\n",
        "\n",
        "  # 2. vocab_dictë¥¼ ì´ìš©í•´ ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
        "  for word in parsed_sent:\n",
        "    if word in vocab_dict: input_id.append(vocab_dict[word])\n",
        "    else: input_id.append(vocab_dict[\"[OOV]\"])\n",
        "  \n",
        "  # ë‹¨ì¼ ë¬¸ì¥ ì¶”ë¡ ì´ê¸° ë•Œë¬¸ì— íŒ¨ë”©í•  í•„ìš”ê°€ ì—†ìŒ \n",
        "  score = mymodel.predict(np.array([input_id])) \n",
        "\n",
        "  print(\"** INPUT:\", sentence)\n",
        "  print(\"   -> ë¶€ì •: {:.2f} / ê¸ì •: {:.2f}\".format(score[0][0],score[0][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm172c7-YmBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1 = \"ì‹œê°„ ê°€ëŠ” ì¤„ ì•Œê³  ë´¤ìŠµë‹ˆë‹¤.\"\n",
        "sentence2 = \"ì•ˆë³´ë©´ í›„íšŒã… ã… ...\"\n",
        "inference(model, sentence1)\n",
        "inference(model, sentence2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi_fIiVC4k8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ì›í•˜ëŠ” ë¬¸ì¥ì— ëŒ€í•´ ì¶”ë¡ í•´ ë³´ì„¸ìš”\n",
        "inference(model, \"ë°•ì„œì¤€ì´ ë‹¤í–ˆë”°\")\n",
        "inference(model, \"ê¿€ì  ì¤ìŠµë‹ˆë‹¤\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_NVAg9E7F3c",
        "colab_type": "text"
      },
      "source": [
        "# # 3. ë‚˜ë§Œì˜ ëª¨ë¸ ë§Œë“¤ì–´ë³´ê¸° "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMo6UCv78uGz",
        "colab_type": "text"
      },
      "source": [
        "# ì‹¤ìŠµ MISSION #16\n",
        ">  LSTM, Dense layer ë“±ì„ ììœ ë¡­ê²Œ í™œìš©í•´ì„œ ìì‹ ë§Œì˜ ëª¨ë¸ì„ ë§Œë“¤ê³  \n",
        "ì´í›„ TEST ë°ì´í„°ì— ëŒ€í•´ ìµœì¢… ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ì„¸ìš”\n",
        "</font>\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EJxGxXl4MJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        " \n",
        "\n",
        "# 1. ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n",
        "model2 = tf.keras.Sequential([\n",
        "\n",
        "      # MISSION ì‘ì„± #\n",
        "\n",
        "      ################                 \n",
        "\n",
        "]) \n",
        "\n",
        "# 2. optimizer, loss ì„ íƒí•˜ê¸°\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 3. ëª¨ë¸ í›ˆë ¨í•˜ê¸°\n",
        "num_epochs = 5\n",
        "history = model2.fit(train_input_ids, train_label_ids, epochs=num_epochs, validation_data=(val_input_ids, val_label_ids), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhibjqAt69vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. ëª¨ë¸ ì§„ë‹¨í•˜ê¸°\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmDzbNJ7DfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ í‰ê°€í•˜ê¸°\n",
        "\n",
        "model2.evaluate(test_input_ids, test_label_ids, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2HnsxdPgRUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ìƒ˜í”Œ ì˜ˆì œì— ëŒ€í•´ ì¶”ë¡ í•´ ë³´ì„¸ìš” \n",
        "\n",
        "inference(model2, \"ë¬¼ì´ ë°˜ë„ ì•ˆë‚¨ì•˜ë‹¤\")  #ë¶€ì •\n",
        "inference(model2, \"ë¬¼ì´ ë°˜ì´ë‚˜ ë‚¨ì•˜ë‹¤\")  #ê¸ì •\n",
        "inference(model2, \"ì£„ì†¡í•˜ì§€ë§Œ í˜¹ì‹œ ì‹¤ë¡€ê°€ ì•ˆëœë‹¤ë©´ êº¼ì ¸ì£¼ì‹¤ìˆ˜ ìˆìœ¼ì‹ ì§€ã…ã…?\") #ë¶€ì •\n",
        "inference(model2, \"ì˜í•˜ëŠ” ì§“ì´ë‹¤\") #ë¶€ì •\n",
        "inference(model2, \"ê°€ê²Œ ì™¸ê´€ì€ êµ¬ë¦°ë° ë§›ì€ ã…‡ã…ˆ\") #ê¸ì •\n",
        "inference(model2, \"ã„·ã„· ê°„ë§Œì— ê°“ëµì‘ ã„·ã„·ã„·\") #ê¸ì •\n",
        "inference(model2, \"ì£¼ì¸ê³µ ì»¤ì—¬ì›Œ ã… ã… \") #ê¸ì •\n",
        "inference(model2, \"OTL\") #ë¶€ì •\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y_E831p2KJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}