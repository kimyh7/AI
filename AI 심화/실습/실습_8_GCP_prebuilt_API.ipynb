{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습_8_GCP_prebuilt-API",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNZloR0FAmW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5EgSNLvXywU",
        "colab_type": "text"
      },
      "source": [
        "# Google Cloud Platform - ML API 사용하기.\n",
        "\n",
        "본 노트북은 [이 노트북](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/CPB100/lab4c/mlapis.ipynb)을 교육 과정에 맞추어 업그레이드한 버전인 것을 밝힙니다.\n",
        "\n",
        "\n",
        "## Getting a Google API Credential.\n",
        "\n",
        "처음 해야할 것은 Google Cloud APIs에 대한 사용 권한을 얻는 것!\n",
        "\n",
        "프로젝트를 만들고 나면 [API console](http://console.cloud.google.com/apis)에서 좌측 메뉴의 \"사용자 인증정보(Credentials)\"를 클릭. 이후 \"사용자 인증정보 생성(Create Credentials)\"를 선택하고 어플리케이션을 위한 API key를 생성한다.\n",
        "\n",
        "악용 방지를 위해 API의 사용을 특정 IP로 제한하는 등의 조치가 필요하나 현재 이 데모를 위해서는 신경쓰지 않기로 한다.\n",
        "\n",
        "\n",
        "API key를 할당 받았으면, 아래 셀을 실행한 후 나오는 텍스트박스에 키를 입력한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqP3ISKr_wRP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxMSTfPdfoaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import getpass \n",
        "APIKEY = getpass.getpass()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w4bHiuYXywg",
        "colab_type": "text"
      },
      "source": [
        "API 콘솔에서, 왼쪽 메뉴의 \"대시보드(Dashboard)\"를 선택하고, \"AI 및 서비스 사용 설정\"를 클릭하세요.\n",
        "\n",
        "프로젝트에 대해 다음 API들을 사용 가능하도록 설정하세요.\n",
        "<ol>\n",
        "<li> Google Translate API </li>\n",
        "<li> Google Cloud Vision API </li>\n",
        "<li> Google Natural Language API </li>\n",
        "<li> Google Cloud Speech-to-text API </li>\n",
        "</ol> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTdwxe76Xywy",
        "colab_type": "text"
      },
      "source": [
        "## Translate API 호출\n",
        "\n",
        "[Google Cloud Translation](https://cloud.google.com/translate/docs/) 문서를 확인.\n",
        "[지원언어 목록](https://cloud.google.com/translate/docs/languages)\n",
        "\n",
        "이는 Service의 형태로, 노트북이 실행되는 VM에서 translation이 수행되는 것이 아님.\n",
        "\n",
        "클라우드 컴퓨팅의 강점 중 하나!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjjvlaPkXyw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# running Translate API\n",
        "from googleapiclient.discovery import build\n",
        "service = build('translate', 'v2', developerKey=APIKEY)\n",
        "\n",
        "# use the service\n",
        "#inputs = ['is it really this easy?', 'amazing technology', 'wow']\n",
        "inputs = ['이게 정말 그렇게 쉬워?', '우리 집 강아지는 골든리트리버야.', '번역이 수행되는 것을 확인할 수 있습니다.']\n",
        "outputs = service.translations().list(source='ko', target='en', q=inputs).execute()\n",
        "# print outputs\n",
        "for input, output in zip(inputs, outputs['translations']):\n",
        "  print(u\"{0} -> {1}\".format(input, output['translatedText']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tueBLHcXXyw6",
        "colab_type": "text"
      },
      "source": [
        "한일 번역도 잘 수행되는 것을 확인할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiUqUjZoXyw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = service.translations().list(source='ko', target='ja', q=inputs).execute()\n",
        "# print outputs\n",
        "for input, output in zip(inputs, outputs['translations']):\n",
        "  print(u\"{0} -> {1}\".format(input, output['translatedText']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqvz5erXyxE",
        "colab_type": "text"
      },
      "source": [
        "## Vision API 호출\n",
        "\n",
        "[Vision API](https://cloud.google.com/vision/docs/)는 Cloud Storage에서 이미지를 처리하거나 POST 메시지에 직접 포함시킬 수 있음.\n",
        "\n",
        "Vision API는 이미지 파일의 콘텐츠를 요청 본문에 [base64](https://cloud.google.com/vision/docs/base64)로 인코딩된 문자열로 전송하여 로컬 이미지 파일에서 기능 감지를 수행 가능함.\n",
        "\n",
        "[request 안내](https://cloud.google.com/vision/docs/request)의 형태로 Vision API는 요청을 보냄.\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/cloud-samples-data/vision/using_curl/shanghai.jpeg\" width = \"400\"/>.\n",
        "\n",
        "\n",
        "위 사진에 대해 Cloud Storage를 사용하고 OCR을 수행."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakobiRlM8xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running Vision API\n",
        "import base64\n",
        "IMAGE=\"gs://cloud-samples-data/vision/using_curl/shanghai.jpeg\"\n",
        "#IMAGE=\"https://storage.cloud.google.com/cloud-samples-data/vision/using_curl/shanghai.jpeg\"\n",
        "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
        "request = vservice.images().annotate(body={\n",
        "      \"requests\": [\n",
        "        {\n",
        "          \"image\": {\n",
        "            \"source\": {\n",
        "              \"imageUri\": IMAGE\n",
        "            }\n",
        "          },\n",
        "          \"features\": [\n",
        "            {\n",
        "              \"type\": \"LABEL_DETECTION\",\n",
        "              \"maxResults\": 3\n",
        "            },\n",
        "            {\n",
        "              \"type\": \"OBJECT_LOCALIZATION\",\n",
        "              \"maxResults\": 1\n",
        "            },\n",
        "            {\n",
        "              \"type\": \"TEXT_DETECTION\",\n",
        "              \"maxResults\": 1,\n",
        "              \"model\": \"builtin/latest\"\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    })\n",
        "#responses = request.execute(num_retries=3)\n",
        "responses = request.execute()\n",
        "print('Label Annotations of LABEL_DETECTION')\n",
        "print(responses['responses'][0]['labelAnnotations'][0])\n",
        "print(responses['responses'][0]['labelAnnotations'][1])\n",
        "print(responses['responses'][0]['labelAnnotations'][2])\n",
        "print()\n",
        "print('Local Object Annotations of OBJECT_LOCALIZATION')\n",
        "print(responses['responses'][0]['localizedObjectAnnotations'][0])\n",
        "print()\n",
        "print('Text Annotations of TEXT_DETECTION')\n",
        "print(responses['responses'][0]['textAnnotations'][0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buuu_L0SXyxa",
        "colab_type": "text"
      },
      "source": [
        "## 간판 OCR 및 번역\n",
        "\n",
        "중국어 간판.. Google Cloud Vision API를 통해 읽은 후 번역해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV5eme6HmDp2",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/cloud-training-demos/vision/sign2.jpg\" width = \"400\"/>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dvkV5Ucplh3Z",
        "colab": {}
      },
      "source": [
        "# Running Vision API\n",
        "import base64\n",
        "IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
        "\n",
        "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
        "request = vservice.images().annotate(body={\n",
        "        'requests': [{\n",
        "                'image': {\n",
        "                    'source': {\n",
        "                        'gcs_image_uri': IMAGE\n",
        "                    }\n",
        "                },\n",
        "                'features': [{\n",
        "                    'type': 'TEXT_DETECTION',\n",
        "                    'maxResults': 3,\n",
        "                }]\n",
        "            }],\n",
        "        })\n",
        "responses = request.execute(num_retries=3)\n",
        "print(responses['responses'][0]['textAnnotations'][0]['description'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLejJ0ynnCEN",
        "colab_type": "text"
      },
      "source": [
        "대략 잘 인식한 것 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sz3-rjyNlgwG",
        "colab": {}
      },
      "source": [
        "foreigntext = responses['responses'][0]['textAnnotations'][0]['description']\n",
        "foreignlang = responses['responses'][0]['textAnnotations'][0]['locale']\n",
        "print('Language Code = {}.  \\nText:\\n{}'.format(foreignlang,foreigntext))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2qHr_3am5vL",
        "colab_type": "text"
      },
      "source": [
        "정보를 확인하면, 현재 중국어 간체로 인식했음을 확인할 수 있다.\n",
        "\n",
        "해당 출력물에 아까 수행했던 translation API를 적용하면 아래와 같이 번역 결과를 얻을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bte0ys8Xyxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs=[foreigntext]\n",
        "outputs = service.translations().list(source=foreignlang, target='en', q=inputs).execute()\n",
        "#outputs = service.translations().list(source=foreignlang, target='ko', q=inputs).execute()\n",
        "# print outputs\n",
        "for input, output in zip(inputs, outputs['translations']):\n",
        "  print(u\"{0} -> {1}\".format(input, output['translatedText']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WIrguLjXyx0",
        "colab_type": "text"
      },
      "source": [
        "## Language API를 통한 감성 분석\n",
        "\n",
        "\n",
        "[Google Cloud Natural Language API](https://cloud.google.com/natural-language/docs/) 를 사용하여 텍스트 감성을 분석해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tqux2TOXyx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lservice = build('language', 'v1', developerKey=APIKEY)\n",
        "quotes = [\n",
        "  '이 영화는 정말 재밌어! 다음에 또 보고싶구만.',\n",
        "  '이거 진짜 별로임 제발 보지 마세요.',\n",
        "  '말 같지도 않은 소리 하고있네',\n",
        "  '다음에는 좀 더 잘할 수 있을거에요.', \n",
        "  '우와 너 잘하는구나!',\n",
        "  '으이구 참 잘들하는 짓이다'\n",
        "]\n",
        "for quote in quotes:\n",
        "  response = lservice.documents().analyzeSentiment(\n",
        "    body={\n",
        "      'document': {\n",
        "         'type': 'PLAIN_TEXT',\n",
        "         'content': quote\n",
        "      }\n",
        "    }).execute()\n",
        "  score = response['documentSentiment']['score']\n",
        "  magnitude = response['documentSentiment']['magnitude']\n",
        "  print('SCORE=%s MAGNITUDE=%s for %s' % (score, magnitude, quote))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPFj_IGul6Yp",
        "colab_type": "text"
      },
      "source": [
        "[감정분석 가이드](https://cloud.google.com/natural-language/docs/basics#interpreting_sentiment_analysis_values) 에 따르면 Score는 전반적인 정서, Magnitude는 그 양입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LRa6r8aXyyI",
        "colab_type": "text"
      },
      "source": [
        "##VIsion API를 이용한 이미지의 인물 감정 분석A\n",
        "> API 문서 참고 : https://cloud.google.com/vision/docs/detecting-faces\n",
        "### Sample Images\n",
        "<img src=\"https://cdn.pixabay.com/photo/2018/03/28/04/59/child-3268265_960_720.jpg\" width = \"300\"/>\n",
        "<figcaption>Image 1</figcaption>\n",
        "<img src=\"https://cdn.pixabay.com/photo/2017/10/11/08/03/surprise-2840248_960_720.jpg\" width = \"300\"/>\n",
        "<figcaption>Image 2</figcaption>\n",
        "<img src=\"https://cdn.pixabay.com/photo/2016/11/16/10/28/girl-1828541_960_720.jpg\" width = \"300\"/>\n",
        "<figcaption>Image 3</figcaption>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWXZea4KnyBb",
        "colab": {}
      },
      "source": [
        "def emotion_detector(apikey, image):\n",
        "    vservice = build('vision', 'v1', developerKey=apikey)\n",
        "    request = vservice.images().annotate(body={\n",
        "        'requests': [{\n",
        "                'image': {\n",
        "                    'source': {\n",
        "                        #'gcsImageUri': image\n",
        "                        \"imageUri\": image\n",
        "                    }\n",
        "                },\n",
        "                'features': [{\n",
        "                    'type': 'FACE_DETECTION'\n",
        "                }]\n",
        "            }],\n",
        "        })\n",
        "    responses = request.execute()\n",
        "    ## 추출되는 키값들.\n",
        "    #print(responses['responses'][0]['faceAnnotations'][0].keys())\n",
        "    annotation = responses['responses'][0]['faceAnnotations'][0]\n",
        "    return {'Surprise':annotation['surpriseLikelihood'],\n",
        "            'Joy':annotation['joyLikelihood'],\n",
        "            'Sorrow':annotation['sorrowLikelihood']}\n",
        "\n",
        "IMAGE1=\"https://cdn.pixabay.com/photo/2018/03/28/04/59/child-3268265_960_720.jpg\"\n",
        "IMAGE2=\"https://cdn.pixabay.com/photo/2017/10/11/08/03/surprise-2840248_960_720.jpg\"\n",
        "IMAGE3=\"https://cdn.pixabay.com/photo/2016/11/16/10/28/girl-1828541_960_720.jpg\"\n",
        "print(emotion_detector(APIKEY, IMAGE1))\n",
        "print(emotion_detector(APIKEY, IMAGE2))\n",
        "print(emotion_detector(APIKEY, IMAGE3))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMgp1T0FXyy8",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2018 Google Inc.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpySj3XUXyzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}