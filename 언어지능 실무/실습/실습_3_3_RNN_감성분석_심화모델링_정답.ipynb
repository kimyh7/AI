{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습_3_3_RNN_감성분석_심화모델링_정답.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQuwLrfneJGq"
      },
      "source": [
        "# 실습 3. RNN을 이용한 😀감정분석😑 모델 학습하기\n",
        "\n",
        "\n",
        "\n",
        "<b>학습 목표:    \n",
        "- LSTM, GRU 등 다양한 RNN 계열 셀들을 활용해본다.\n",
        "- Bidirectional RNN, Multi-layer RNN, 모델 앙상블을 모델링해본다.\n",
        "</b>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5VEKjCVzQz"
      },
      "source": [
        "## #0. 실습 준비하기\n",
        "지난 실습에서는 SimpleRNN을 사용해 감성분석 모델링을 진행했습니다.    \n",
        "이번 시간에는 이론으로 학습한 다양한 셀 구조와 모델 아키텍처를 사용해 모델링을 진행해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cg9V5xCV-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60c06b2d-a83e-435b-8ef8-97ff36edd8e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ695haKKAwv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20a77c31-0ae3-4d87-fb4e-25d0cd1a1e14"
      },
      "source": [
        "## train, validation, test 데이터 로딩\n",
        "!cp \"/content/gdrive/My Drive/NLP/utils.py\" \"/content\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_prepro_data.pkl\", \"rb\") as f:\n",
        "  prepro_data = pickle.load(f)\n",
        "train_ids = prepro_data[\"train_ids\"]\n",
        "train_labels = prepro_data[\"train_labels\"]\n",
        "val_ids = prepro_data[\"val_ids\"]\n",
        "val_labels = prepro_data[\"val_labels\"]\n",
        "test_ids = prepro_data[\"test_ids\"]\n",
        "test_labels = prepro_data[\"test_labels\"]\n",
        "label_map = prepro_data[\"label_map\"]\n",
        "print(len(train_ids), len(train_labels), len(val_ids), len(val_labels), len(test_ids), len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49999 49999 9999 9999 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMDpntkKOY7"
      },
      "source": [
        "## 단어사전 & text_encoder 로딩\n",
        "from utils import TextEncoder\n",
        "import json\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_vocab.json\", \"r\") as f:\n",
        "  new_vocab_list = json.loads(f.read())\n",
        "\n",
        "text_encoder = TextEncoder(new_vocab_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Cnajwnc73B"
      },
      "source": [
        "\"\"\" CBOW 워드벡터 로딩 \"\"\"\n",
        "\n",
        "## final_embeddings: 70002개 토큰에 대한 워드 벡터 매트릭스 shape=(70002, 128)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/NLP/vecs.tsv\") as f:\n",
        "  vecs = [v.strip() for v in f.readlines()]\n",
        "  final_embeddings = [v.split(\"\\t\") for v in vecs]\n",
        "  final_embeddings = np.array(final_embeddings, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zo7pgURKdFq"
      },
      "source": [
        "## #1. 모델링 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39iPCdwGTjzk"
      },
      "source": [
        "### MODEL1: LSTM 셀 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u21E5JCF75xX"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAQKP1aQI0G5"
      },
      "source": [
        "LSTM 셀은 tensorflow.keras.layers에 있는 LSTM 레이어를 사용하면 됩니다.   \n",
        "사용하는 방법은 SimpleRNN과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcDr8GlZTqqV"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlpgWelVIMXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "2307de79-a362-4437-d28c-40b23d5c13fc"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,037,364\n",
            "Trainable params: 11,037,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJZ8o6v7kih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1101e535-635b-49a5-a71d-503506d9ae5a"
      },
      "source": [
        "\"\"\"CBOW로 학습된 워드 임베딩을 Initialize 해주기\"\"\"\n",
        "import random\n",
        "org_vocab_size = final_embeddings.shape[0]\n",
        "rand_initial = np.random.uniform(-1,1,size=[vocab_size-org_vocab_size,embedding_dim])\n",
        "# CBOW 학습된 임베딩 + 랜덤 initialize한 weight를 모델의 weight에 대입\n",
        "initial_weight = np.append(final_embeddings, rand_initial, axis = 0)\n",
        "model1.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nPJiGW1q92"
      },
      "source": [
        "## 모델 컴파일\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9vODjnL8KuZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "4325175e-60ec-48c8-8b92-5fcdb490ecb0"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.4987 - accuracy: 0.7482 - val_loss: 0.4060 - val_accuracy: 0.8146\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.3459 - accuracy: 0.8489 - val_loss: 0.3815 - val_accuracy: 0.8318\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.2834 - accuracy: 0.8829 - val_loss: 0.3906 - val_accuracy: 0.8343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT1NNPJ2fdE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2fe12c2e-3fdb-49c4-bccf-ae33a22d26de"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model1.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40304747223854065, 0.8267999887466431]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFxF0B3SjgOh"
      },
      "source": [
        "### MODEL2: Bi-LSTM 모델 만들기\n",
        "\n",
        "Bi-RNN 모델은 keras.layers의 Bidirectional Layer로 RNN계열 레이어를 감싸서 코딩할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7tbxfLsjLOD"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     Bidirectional(LSTM(rnn_hidden_dim)),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9xC_2XgkT76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "69ec3936-645d-4528-ec9b-587bf173657b"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100)               71600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,075,664\n",
            "Trainable params: 11,075,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XbyBe5ZJI8a"
      },
      "source": [
        "👉bidirectional 레이어를 타고 나온 hidden vector의 차원이 100차원인 것을 확인할 수 있습니다.   \n",
        "orward LSTM에서 나온 50차원의 벡터와 backward LSTM에서 나온 50차원의 벡터를 concatenate했기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925t5x3jkZuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6397d371-c835-48ba-e75d-62526d804695"
      },
      "source": [
        "model2.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzLqEbAHkeZ0"
      },
      "source": [
        "## 모델 컴파일\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIsxg_ifkhlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "87cc93c4-4e3f-42a5-f399-d00289ae8d2d"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.5003 - accuracy: 0.7436 - val_loss: 0.3966 - val_accuracy: 0.8180\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.3420 - accuracy: 0.8514 - val_loss: 0.3775 - val_accuracy: 0.8292\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.2783 - accuracy: 0.8844 - val_loss: 0.3872 - val_accuracy: 0.8332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuLPw7XGkktO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2c5857df-58f1-4573-f096-032f0f3a07c7"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model2.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4033 - accuracy: 0.8225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40331748127937317, 0.8224999904632568]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAAvjbqokw7o"
      },
      "source": [
        "### MODEL3: Multi-layer-LSTM 모델 만들기\n",
        "\n",
        "Multi-layer RNN 모델을 만들기 위해서는 하단의 RNN 레이어에서 return_sequences 옵션을 True로 설정해야 합니다.   \n",
        "다음 레이어에서는 이전 레이어에서 반환한 시퀀스 hidden state를 인풋으로 받기 때문입니다.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23lOVrGvkmMe"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences = True),\n",
        "     Dropout(0.2),\n",
        "     LSTM(rnn_hidden_dim, return_sequences = False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxHufNhlEJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "4f2c67bb-cd26-4621-8062-015f011cb4ed"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,046,214\n",
            "Trainable params: 11,046,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY4hiTajlGUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "661e1f9c-b024-45a0-df08-76f3ea315c5f"
      },
      "source": [
        "model3.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mAFetXAlK4A"
      },
      "source": [
        "## 모델 컴파일\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78FuhlmlOgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "120163e7-0cd7-4815-badc-b7482d50354e"
      },
      "source": [
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 78ms/step - loss: 0.4984 - accuracy: 0.7496 - val_loss: 0.3940 - val_accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.3467 - accuracy: 0.8489 - val_loss: 0.3812 - val_accuracy: 0.8301\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.2883 - accuracy: 0.8809 - val_loss: 0.3766 - val_accuracy: 0.8375\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.2432 - accuracy: 0.9028 - val_loss: 0.3888 - val_accuracy: 0.8359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvsQmKzlRBL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a3a06fe8-45e3-4dcf-db35-24ea6e61c21c"
      },
      "source": [
        "## 테스트 데이터에 대해 성능 평가\n",
        "model3.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3978 - accuracy: 0.8305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3978496193885803, 0.8305000066757202]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BmzCfNmCE3"
      },
      "source": [
        "### MODEL4: 세 모델의 결과 앙상블하기\n",
        "마지막으로 위에서 학습한 세 모델을 앙상블하는 코드입니다.   \n",
        "세 개의 모델을 독립적으로 학습한 후 결과를 앙상블하면 정확도를 높일 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEFTHlblT2y"
      },
      "source": [
        "def predict(test_ids):\n",
        "  res1 = model1.predict(test_ids)\n",
        "  res2 = model2.predict(test_ids)\n",
        "  res3 = model3.predict(test_ids)\n",
        "  result = (res1 + res2 + res3) / 3\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzww4mdzm28X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8dd2cf6a-e194-4f45-fa3f-c092c095e60d"
      },
      "source": [
        "prediction = predict(test_ids)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6829951 , 0.31700495],\n",
              "       [0.68486124, 0.3151388 ],\n",
              "       [0.36904716, 0.63095284],\n",
              "       ...,\n",
              "       [0.9821079 , 0.01789213],\n",
              "       [0.9926901 , 0.00730986],\n",
              "       [0.06264149, 0.93735856]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgttjzZ0GHV"
      },
      "source": [
        "👉predict 함수는 세 모델이 예측한 결과를 평균한 확률값을 아웃풋으로 반환합니다.    \n",
        "\n",
        "최종적으로 예측을 하기 위해서는 이 확률값을 카테고리로 변경해야 하겠지요?   \n",
        "np.argmax 함수는 주어진 축에 대해 최대값의 위치를 찾아주는 함수입니다.   \n",
        "이 함수를 사용해 확률값이 가장 높은 카테고리를 모델 예측치로 사용할 수 있습니다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdH4Z7Ulm6JC"
      },
      "source": [
        "\"\"\" catecory로 변경 \"\"\"\n",
        "prediction = np.argmax(prediction, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TycNYyY5nI4l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2075bade-67e5-409b-d13e-fc5f6792dafb"
      },
      "source": [
        "print(\"TEST ACCURACY:\")\n",
        "sum(prediction == test_labels) / len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SUIcOx7KWGP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3yyOsTqKiR_"
      },
      "source": [
        "## #2. DAILY MISSION 🙌\n",
        "\n",
        "아래의 세 모델은 RNN을 사용하여 만든 감성분석 모델입니다.   \n",
        "그런데 무슨 문제인지, 학습이 잘 이루어지지 않고 있습니다.   \n",
        "모델을 살펴보고, 어떤 오류가 있는지 찾아 디버깅한 후 파일을 제출해주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh7ugE6YLqHJ"
      },
      "source": [
        "#### model_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_8MkMZZKYpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fda0205d-153c-4239-f2fe-061980d48de1"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     GRU(rnn_hidden_dim),\n",
        "     Dense(2, activation = \"softmax\")]\n",
        ")\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 50)                27000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,026,014\n",
            "Trainable params: 11,026,014\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zoNJrL0LbG4"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ylbdC4LOtJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "344dd12a-98a8-4409-ba6c-7711aa057ec4"
      },
      "source": [
        "model_1.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.8221 - accuracy: 0.4986 - val_loss: 0.7365 - val_accuracy: 0.5001\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 67ms/step - loss: 0.7353 - accuracy: 0.5045 - val_loss: 0.7196 - val_accuracy: 0.5095\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 68ms/step - loss: 0.7098 - accuracy: 0.5132 - val_loss: 0.7219 - val_accuracy: 0.5040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF0s5gmELuPF"
      },
      "source": [
        "#### model_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-rFAuoLXag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "d1b18c25-4939-48a4-9630-5cb8ae21e9ae"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, None, 50)          15300     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 2)           102       \n",
            "=================================================================\n",
            "Total params: 11,041,314\n",
            "Trainable params: 11,041,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skBuhBsMAFy"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQJ7Ewv5L4Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "3c14110c-1e96-4430-f5b2-788d00d82e71"
      },
      "source": [
        "model_2.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-de8b7cb03c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m history = model_2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(val_ids, val_labels), callbacks=[callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [200 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [200 50]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-41-de8b7cb03c64>:9) ]]\n\t [[ConstantFolding/broadcast_weights_1/assert_broadcastable/AssertGuard/switch_pred/_14_const_false/_61]]\n  (1) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [200 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [200 50]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-41-de8b7cb03c64>:9) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_81116]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLDlRLqMDnS"
      },
      "source": [
        "#### model_3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q48ENcMFS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9731344e-f7c1-4ddd-faaf-5e4cd5e03161"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # 단어사전 개수\n",
        "embedding_dim = final_embeddings.shape[1] # 임베딩 차원\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 11,034,763\n",
            "Trainable params: 11,034,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfsVmqCyMCSB"
      },
      "source": [
        "- 오류가 있는 부분:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_gfBUEMFPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8d1c03c9-459a-4a23-b6ab-eab41d755dfe"
      },
      "source": [
        "model_3.weights[0].assign(initial_weight)\n",
        "## 모델 컴파일\n",
        "model_3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## 모델 학습\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 72ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.4961\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}