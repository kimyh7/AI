{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ì‹¤ìŠµ_3_3_RNN_ê°ì„±ë¶„ì„_ì‹¬í™”ëª¨ë¸ë§_ì •ë‹µ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQuwLrfneJGq"
      },
      "source": [
        "# ì‹¤ìŠµ 3. RNNì„ ì´ìš©í•œ ğŸ˜€ê°ì •ë¶„ì„ğŸ˜‘ ëª¨ë¸ í•™ìŠµí•˜ê¸°\n",
        "\n",
        "\n",
        "\n",
        "<b>í•™ìŠµ ëª©í‘œ:    \n",
        "- LSTM, GRU ë“± ë‹¤ì–‘í•œ RNN ê³„ì—´ ì…€ë“¤ì„ í™œìš©í•´ë³¸ë‹¤.\n",
        "- Bidirectional RNN, Multi-layer RNN, ëª¨ë¸ ì•™ìƒë¸”ì„ ëª¨ë¸ë§í•´ë³¸ë‹¤.\n",
        "</b>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5VEKjCVzQz"
      },
      "source": [
        "## #0. ì‹¤ìŠµ ì¤€ë¹„í•˜ê¸°\n",
        "ì§€ë‚œ ì‹¤ìŠµì—ì„œëŠ” SimpleRNNì„ ì‚¬ìš©í•´ ê°ì„±ë¶„ì„ ëª¨ë¸ë§ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.    \n",
        "ì´ë²ˆ ì‹œê°„ì—ëŠ” ì´ë¡ ìœ¼ë¡œ í•™ìŠµí•œ ë‹¤ì–‘í•œ ì…€ êµ¬ì¡°ì™€ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ë§ì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cg9V5xCV-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60c06b2d-a83e-435b-8ef8-97ff36edd8e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ695haKKAwv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20a77c31-0ae3-4d87-fb4e-25d0cd1a1e14"
      },
      "source": [
        "## train, validation, test ë°ì´í„° ë¡œë”©\n",
        "!cp \"/content/gdrive/My Drive/NLP/utils.py\" \"/content\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_prepro_data.pkl\", \"rb\") as f:\n",
        "  prepro_data = pickle.load(f)\n",
        "train_ids = prepro_data[\"train_ids\"]\n",
        "train_labels = prepro_data[\"train_labels\"]\n",
        "val_ids = prepro_data[\"val_ids\"]\n",
        "val_labels = prepro_data[\"val_labels\"]\n",
        "test_ids = prepro_data[\"test_ids\"]\n",
        "test_labels = prepro_data[\"test_labels\"]\n",
        "label_map = prepro_data[\"label_map\"]\n",
        "print(len(train_ids), len(train_labels), len(val_ids), len(val_labels), len(test_ids), len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49999 49999 9999 9999 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMDpntkKOY7"
      },
      "source": [
        "## ë‹¨ì–´ì‚¬ì „ & text_encoder ë¡œë”©\n",
        "from utils import TextEncoder\n",
        "import json\n",
        "with open(\"/content/gdrive/My Drive/NLP/Sentiment_vocab.json\", \"r\") as f:\n",
        "  new_vocab_list = json.loads(f.read())\n",
        "\n",
        "text_encoder = TextEncoder(new_vocab_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Cnajwnc73B"
      },
      "source": [
        "\"\"\" CBOW ì›Œë“œë²¡í„° ë¡œë”© \"\"\"\n",
        "\n",
        "## final_embeddings: 70002ê°œ í† í°ì— ëŒ€í•œ ì›Œë“œ ë²¡í„° ë§¤íŠ¸ë¦­ìŠ¤ shape=(70002, 128)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/NLP/vecs.tsv\") as f:\n",
        "  vecs = [v.strip() for v in f.readlines()]\n",
        "  final_embeddings = [v.split(\"\\t\") for v in vecs]\n",
        "  final_embeddings = np.array(final_embeddings, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zo7pgURKdFq"
      },
      "source": [
        "## #1. ëª¨ë¸ë§ ì‹¤ìŠµ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39iPCdwGTjzk"
      },
      "source": [
        "### MODEL1: LSTM ì…€ ì‚¬ìš©í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u21E5JCF75xX"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAQKP1aQI0G5"
      },
      "source": [
        "LSTM ì…€ì€ tensorflow.keras.layersì— ìˆëŠ” LSTM ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.   \n",
        "ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ SimpleRNNê³¼ ë™ì¼í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcDr8GlZTqqV"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlpgWelVIMXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "2307de79-a362-4437-d28c-40b23d5c13fc"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,037,364\n",
            "Trainable params: 11,037,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJZ8o6v7kih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1101e535-635b-49a5-a71d-503506d9ae5a"
      },
      "source": [
        "\"\"\"CBOWë¡œ í•™ìŠµëœ ì›Œë“œ ì„ë² ë”©ì„ Initialize í•´ì£¼ê¸°\"\"\"\n",
        "import random\n",
        "org_vocab_size = final_embeddings.shape[0]\n",
        "rand_initial = np.random.uniform(-1,1,size=[vocab_size-org_vocab_size,embedding_dim])\n",
        "# CBOW í•™ìŠµëœ ì„ë² ë”© + ëœë¤ initializeí•œ weightë¥¼ ëª¨ë¸ì˜ weightì— ëŒ€ì…\n",
        "initial_weight = np.append(final_embeddings, rand_initial, axis = 0)\n",
        "model1.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nPJiGW1q92"
      },
      "source": [
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9vODjnL8KuZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "4325175e-60ec-48c8-8b92-5fcdb490ecb0"
      },
      "source": [
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.4987 - accuracy: 0.7482 - val_loss: 0.4060 - val_accuracy: 0.8146\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.3459 - accuracy: 0.8489 - val_loss: 0.3815 - val_accuracy: 0.8318\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.2834 - accuracy: 0.8829 - val_loss: 0.3906 - val_accuracy: 0.8343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT1NNPJ2fdE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2fe12c2e-3fdb-49c4-bccf-ae33a22d26de"
      },
      "source": [
        "## í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì„±ëŠ¥ í‰ê°€\n",
        "model1.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40304747223854065, 0.8267999887466431]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFxF0B3SjgOh"
      },
      "source": [
        "### MODEL2: Bi-LSTM ëª¨ë¸ ë§Œë“¤ê¸°\n",
        "\n",
        "Bi-RNN ëª¨ë¸ì€ keras.layersì˜ Bidirectional Layerë¡œ RNNê³„ì—´ ë ˆì´ì–´ë¥¼ ê°ì‹¸ì„œ ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7tbxfLsjLOD"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     Bidirectional(LSTM(rnn_hidden_dim)),\n",
        "     Dense(rnn_hidden_dim, activation= \"relu\"),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9xC_2XgkT76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "69ec3936-645d-4528-ec9b-587bf173657b"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100)               71600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,075,664\n",
            "Trainable params: 11,075,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XbyBe5ZJI8a"
      },
      "source": [
        "ğŸ‘‰bidirectional ë ˆì´ì–´ë¥¼ íƒ€ê³  ë‚˜ì˜¨ hidden vectorì˜ ì°¨ì›ì´ 100ì°¨ì›ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
        "orward LSTMì—ì„œ ë‚˜ì˜¨ 50ì°¨ì›ì˜ ë²¡í„°ì™€ backward LSTMì—ì„œ ë‚˜ì˜¨ 50ì°¨ì›ì˜ ë²¡í„°ë¥¼ concatenateí–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925t5x3jkZuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6397d371-c835-48ba-e75d-62526d804695"
      },
      "source": [
        "model2.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzLqEbAHkeZ0"
      },
      "source": [
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIsxg_ifkhlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "87cc93c4-4e3f-42a5-f399-d00289ae8d2d"
      },
      "source": [
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.5003 - accuracy: 0.7436 - val_loss: 0.3966 - val_accuracy: 0.8180\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.3420 - accuracy: 0.8514 - val_loss: 0.3775 - val_accuracy: 0.8292\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.2783 - accuracy: 0.8844 - val_loss: 0.3872 - val_accuracy: 0.8332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuLPw7XGkktO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2c5857df-58f1-4573-f096-032f0f3a07c7"
      },
      "source": [
        "## í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì„±ëŠ¥ í‰ê°€\n",
        "model2.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4033 - accuracy: 0.8225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40331748127937317, 0.8224999904632568]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAAvjbqokw7o"
      },
      "source": [
        "### MODEL3: Multi-layer-LSTM ëª¨ë¸ ë§Œë“¤ê¸°\n",
        "\n",
        "Multi-layer RNN ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” í•˜ë‹¨ì˜ RNN ë ˆì´ì–´ì—ì„œ return_sequences ì˜µì…˜ì„ Trueë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.   \n",
        "ë‹¤ìŒ ë ˆì´ì–´ì—ì„œëŠ” ì´ì „ ë ˆì´ì–´ì—ì„œ ë°˜í™˜í•œ ì‹œí€€ìŠ¤ hidden stateë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23lOVrGvkmMe"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "final_dim = len(label_map)\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences = True),\n",
        "     Dropout(0.2),\n",
        "     LSTM(rnn_hidden_dim, return_sequences = False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxHufNhlEJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "4f2c67bb-cd26-4621-8062-015f011cb4ed"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,046,214\n",
            "Trainable params: 11,046,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY4hiTajlGUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "661e1f9c-b024-45a0-df08-76f3ea315c5f"
      },
      "source": [
        "model3.weights[0].assign(initial_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(85929, 128) dtype=float32, numpy=\n",
              "array([[-1.2835134e-02,  3.8169596e-02,  1.2824427e-02, ...,\n",
              "        -4.1749455e-02, -6.7193434e-04, -2.5152588e-02],\n",
              "       [-4.3288276e-02, -2.2840855e-01, -3.3235773e-01, ...,\n",
              "        -6.2215126e-01, -2.1829844e-01,  5.5536860e-01],\n",
              "       [ 1.4566300e+00, -6.7591065e-01,  2.8122848e-01, ...,\n",
              "         5.9197694e-01, -2.6638773e-01, -5.2011847e-01],\n",
              "       ...,\n",
              "       [ 3.6430800e-01,  1.3824491e-01,  5.7283497e-01, ...,\n",
              "        -4.5271674e-01, -6.3190216e-01, -8.7267727e-01],\n",
              "       [ 8.0739635e-01,  6.2565893e-01, -2.1986499e-01, ...,\n",
              "        -7.4504662e-01,  1.0706705e-01,  8.4927452e-01],\n",
              "       [-4.1984853e-01, -2.4882808e-01, -4.7447753e-01, ...,\n",
              "         3.4534696e-01,  8.9349687e-01, -6.5144444e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mAFetXAlK4A"
      },
      "source": [
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78FuhlmlOgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "120163e7-0cd7-4815-badc-b7482d50354e"
      },
      "source": [
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 19s 78ms/step - loss: 0.4984 - accuracy: 0.7496 - val_loss: 0.3940 - val_accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.3467 - accuracy: 0.8489 - val_loss: 0.3812 - val_accuracy: 0.8301\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.2883 - accuracy: 0.8809 - val_loss: 0.3766 - val_accuracy: 0.8375\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.2432 - accuracy: 0.9028 - val_loss: 0.3888 - val_accuracy: 0.8359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvsQmKzlRBL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a3a06fe8-45e3-4dcf-db35-24ea6e61c21c"
      },
      "source": [
        "## í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì„±ëŠ¥ í‰ê°€\n",
        "model3.evaluate(test_ids, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3978 - accuracy: 0.8305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3978496193885803, 0.8305000066757202]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BmzCfNmCE3"
      },
      "source": [
        "### MODEL4: ì„¸ ëª¨ë¸ì˜ ê²°ê³¼ ì•™ìƒë¸”í•˜ê¸°\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ì—ì„œ í•™ìŠµí•œ ì„¸ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.   \n",
        "ì„¸ ê°œì˜ ëª¨ë¸ì„ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµí•œ í›„ ê²°ê³¼ë¥¼ ì•™ìƒë¸”í•˜ë©´ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEFTHlblT2y"
      },
      "source": [
        "def predict(test_ids):\n",
        "  res1 = model1.predict(test_ids)\n",
        "  res2 = model2.predict(test_ids)\n",
        "  res3 = model3.predict(test_ids)\n",
        "  result = (res1 + res2 + res3) / 3\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzww4mdzm28X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8dd2cf6a-e194-4f45-fa3f-c092c095e60d"
      },
      "source": [
        "prediction = predict(test_ids)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6829951 , 0.31700495],\n",
              "       [0.68486124, 0.3151388 ],\n",
              "       [0.36904716, 0.63095284],\n",
              "       ...,\n",
              "       [0.9821079 , 0.01789213],\n",
              "       [0.9926901 , 0.00730986],\n",
              "       [0.06264149, 0.93735856]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgttjzZ0GHV"
      },
      "source": [
        "ğŸ‘‰predict í•¨ìˆ˜ëŠ” ì„¸ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ í‰ê· í•œ í™•ë¥ ê°’ì„ ì•„ì›ƒí’‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.    \n",
        "\n",
        "ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì´ í™•ë¥ ê°’ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë³€ê²½í•´ì•¼ í•˜ê² ì§€ìš”?   \n",
        "np.argmax í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì¶•ì— ëŒ€í•´ ìµœëŒ€ê°’ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.   \n",
        "ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í™•ë¥ ê°’ì´ ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ëª¨ë¸ ì˜ˆì¸¡ì¹˜ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdH4Z7Ulm6JC"
      },
      "source": [
        "\"\"\" catecoryë¡œ ë³€ê²½ \"\"\"\n",
        "prediction = np.argmax(prediction, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TycNYyY5nI4l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2075bade-67e5-409b-d13e-fc5f6792dafb"
      },
      "source": [
        "print(\"TEST ACCURACY:\")\n",
        "sum(prediction == test_labels) / len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SUIcOx7KWGP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3yyOsTqKiR_"
      },
      "source": [
        "## #2. DAILY MISSION ğŸ™Œ\n",
        "\n",
        "ì•„ë˜ì˜ ì„¸ ëª¨ë¸ì€ RNNì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“  ê°ì„±ë¶„ì„ ëª¨ë¸ì…ë‹ˆë‹¤.   \n",
        "ê·¸ëŸ°ë° ë¬´ìŠ¨ ë¬¸ì œì¸ì§€, í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§€ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.   \n",
        "ëª¨ë¸ì„ ì‚´í´ë³´ê³ , ì–´ë–¤ ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ ì°¾ì•„ ë””ë²„ê¹…í•œ í›„ íŒŒì¼ì„ ì œì¶œí•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh7ugE6YLqHJ"
      },
      "source": [
        "#### model_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_8MkMZZKYpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fda0205d-153c-4239-f2fe-061980d48de1"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_1 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     GRU(rnn_hidden_dim),\n",
        "     Dense(2, activation = \"softmax\")]\n",
        ")\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 50)                27000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 11,026,014\n",
            "Trainable params: 11,026,014\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zoNJrL0LbG4"
      },
      "source": [
        "- ì˜¤ë¥˜ê°€ ìˆëŠ” ë¶€ë¶„:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ylbdC4LOtJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "344dd12a-98a8-4409-ba6c-7711aa057ec4"
      },
      "source": [
        "model_1.weights[0].assign(initial_weight)\n",
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model_1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_1.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.8221 - accuracy: 0.4986 - val_loss: 0.7365 - val_accuracy: 0.5001\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 17s 67ms/step - loss: 0.7353 - accuracy: 0.5045 - val_loss: 0.7196 - val_accuracy: 0.5095\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 17s 68ms/step - loss: 0.7098 - accuracy: 0.5132 - val_loss: 0.7219 - val_accuracy: 0.5040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF0s5gmELuPF"
      },
      "source": [
        "#### model_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-rFAuoLXag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "d1b18c25-4939-48a4-9630-5cb8ae21e9ae"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_2 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=True),\n",
        "     GRU(rnn_hidden_dim, return_sequences=False),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 50)          27000     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, None, 50)          15300     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 2)           102       \n",
            "=================================================================\n",
            "Total params: 11,041,314\n",
            "Trainable params: 11,041,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skBuhBsMAFy"
      },
      "source": [
        "- ì˜¤ë¥˜ê°€ ìˆëŠ” ë¶€ë¶„:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQJ7Ewv5L4Wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "3c14110c-1e96-4430-f5b2-788d00d82e71"
      },
      "source": [
        "model_2.weights[0].assign(initial_weight)\n",
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-de8b7cb03c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m history = model_2.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(val_ids, val_labels), callbacks=[callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [200 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [200 50]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-41-de8b7cb03c64>:9) ]]\n\t [[ConstantFolding/broadcast_weights_1/assert_broadcastable/AssertGuard/switch_pred/_14_const_false/_61]]\n  (1) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [200 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [200 50]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-41-de8b7cb03c64>:9) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_81116]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLDlRLqMDnS"
      },
      "source": [
        "#### model_3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q48ENcMFS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9731344e-f7c1-4ddd-faaf-5e4cd5e03161"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "vocab_size = text_encoder.vocab_size # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜\n",
        "embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›\n",
        "rnn_hidden_dim = 50 # GRU hidden_size\n",
        "\n",
        "\"\"\" MAKE MODEL \"\"\"\n",
        "model_3 = Sequential(\n",
        "    [Embedding(vocab_size, embedding_dim, mask_zero = True),\n",
        "     LSTM(rnn_hidden_dim),\n",
        "     Dense(2, activation=\"softmax\")]\n",
        ")\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10998912  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 11,034,763\n",
            "Trainable params: 11,034,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfsVmqCyMCSB"
      },
      "source": [
        "- ì˜¤ë¥˜ê°€ ìˆëŠ” ë¶€ë¶„:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_gfBUEMFPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8d1c03c9-459a-4a23-b6ab-eab41d755dfe"
      },
      "source": [
        "model_3.weights[0].assign(initial_weight)\n",
        "## ëª¨ë¸ ì»´íŒŒì¼\n",
        "model_3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## ëª¨ë¸ í•™ìŠµ\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)\n",
        "\n",
        "num_epochs = 5\n",
        "history = model_3.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,\n",
        "                    validation_data=(val_ids, val_labels), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 18s 72ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.4961\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}