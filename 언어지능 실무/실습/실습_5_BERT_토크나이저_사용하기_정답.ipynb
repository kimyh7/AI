{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ì‹¤ìŠµ_BERT_í† í¬ë‚˜ì´ì €_ì‚¬ìš©í•˜ê¸°_ì •ë‹µ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyLlLw0muJK4"
      },
      "source": [
        "# BERT í† í¬ë‚˜ì´ì € ì‹¤ìŠµ\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” êµ¬ê¸€ì—ì„œ ê³µê°œí•œ Multi-lingual BERTë¥¼ ë‹¤ìš´ë¡œë“œí•´ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFKvHZ6zmql8"
      },
      "source": [
        "## #1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ë¡œë”©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg7SJ1s6mxvA"
      },
      "source": [
        "#### â–¶ pipë¡œ bert-for-tf2 ì„¤ì¹˜í•˜ê¸°\n",
        "\n",
        "bert-for-tf2 íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ BERT tokenizerì„ ì•„ì£¼ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    \n",
        "<font color=\"blue\"> ì •ìƒì ì¸ ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•´ ì•„ë˜ konlpy ì„¤ì¹˜ ëª…ë ¹ì–´ ì‹¤í–‰ í›„ [ëŸ°íƒ€ì„]-[ëŸ°íƒ€ì„ ë‹¤ì‹œì‹œì‘]ì„ í´ë¦­í•´ì£¼ì„¸ìš”\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLUI6zuUdTyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "967e3c3e-c32d-4fe4-d569-8c4d75585d33"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install konlpy\n",
        "!pip install jpype1==0.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 10kB 8.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40kB 1.7MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=e5a2de3aae5275c04de615b3485509f585e0fe34ebfc8a4c62cbc196f8a7d998\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=1a2846250fafa29e602b15157c38914e576e73219701fbbef48b520f30639bca\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=d9cab1f7dfb3486dc513e6bcc0822af4ae46c73d649f32b6a56c8a35ee569169\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.4MB 1.6MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 29.0MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, tweepy, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfZQqipinJc-"
      },
      "source": [
        "#### â–¶ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©\n",
        "ë°©ê¸ˆ ì„¤ì¹˜í•œ bert íŒ¨í‚¤ì§€ì™€ TensorFlow Hubë¥¼ ë¡œë”©í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISF7wYaEnVdW"
      },
      "source": [
        "## bert ëª¨ë“ˆ ë¡œë”© & TF hub ì—°ê²°\n",
        "\n",
        "import bert\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6TuaxlQwiob"
      },
      "source": [
        "## #2. ì‚¬ì „í•™ìŠµëœ BERT ëª¨ë¸ ë¡œë”©\n",
        "Tensorflow hubì—ì„œ pretrainëœ ë‹¤êµ­ì–´ BERT ëª¨ë¸ì„ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œì…ë‹ˆë‹¤.   \n",
        "í™ˆí˜ì´ì§€ì—ì„œ Multi-lingula BERTì— í•´ë‹¹í•˜ëŠ” ì£¼ì†Œë¥¼ ë³µì‚¬í•´ BERT_MODEL_HUBì— ì…ë ¥í–ˆìŠµë‹ˆë‹¤. \n",
        "\n",
        "ê·¸ë¦¬ê³  hub.KerasLayer í•¨ìˆ˜ë¥¼ ì´ìš©í•´ bert_layerë¥¼ ê°€ì§€ê³  ì™”ìŠµë‹ˆë‹¤.   \n",
        "ì´ ë ˆì´ì–´ê°€ ë°”ë¡œ Transformer ì¸ì½”ë”ê°€ 12ì¸µ ìŒ“ì—¬ìˆëŠ” BERT ëª¨ë¸ì…ë‹ˆë‹¤.   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvcbF_WliIPs"
      },
      "source": [
        "BERT_MODEL_HUB = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2'\n",
        "\n",
        "# BERT layer ê°€ì ¸ì˜¤ê¸°\n",
        "bert_layer = hub.KerasLayer(BERT_MODEL_HUB, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hktrgEmu3pz"
      },
      "source": [
        "## #3. BERT parsing ì´í•´í•˜ê¸°\n",
        "- BERTì—ì„œëŠ” Wordpiece Tokenizationì„ í†µí•´ í† í°ì„ subtokenìœ¼ë¡œ ìª¼ê°­ë‹ˆë‹¤.    \n",
        "- í•œêµ­ì–´ì˜ ê²½ìš° ì›í˜•ì„ ë³´ì¡´í•˜ëŠ” í˜•íƒœì†Œ ë¶„ì„ì„ ê±°ì¹œ í›„ subtokenìœ¼ë¡œ ìª¼ê°œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.   \n",
        "- ìœ„ì—ì„œ ë¡œë”©í•œ bert_layerì—ì„œ ì‚¬ì „í•™ìŠµì— í™œìš©í•œ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "   - bert.tokenization.bert_tokenization í•¨ìˆ˜ ì‚¬ìš©\n",
        "   - í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì´ìš©í•´ ë¬¸ì¥ì„ í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ìª¼ê°  í›„\n",
        "   - tokenizerì˜ <font color=\"blue\">FullTokenizer</font> ì„ ì‚¬ìš©í•´ Sub-tokenization ì§„í–‰\n",
        "\n",
        "- ìš°ë¦¬ê°€ Pythonìœ¼ë¡œ ì½”ë”©í–ˆë˜ @convert_tokens_to_idsë‚˜ @convert_ids_to_tokensë§¤ì„œë“œê°€ bert íŒ¨í‚¤ì§€ì— ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSu5oGnxwqgd"
      },
      "source": [
        "#### Step 1. í† í¬ë‚˜ì´ì € ë¡œë”©í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsSbSQ10uj7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6f1661d4-5a8f-47f1-ed2f-49925755dcf7"
      },
      "source": [
        "from  bert.tokenization import bert_tokenization\n",
        "\n",
        "# vocab_file ê°€ì ¸ì˜¤ê¸°\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "\n",
        "# ì†Œë¬¸ìí™”ë¥¼ í•˜ëŠ”ì§€ ì—¬ë¶€ ê°€ì ¸ì˜¤ê¸°\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ë¡œë”©\n",
        "print(\"vocab file:\", vocab_file)\n",
        "print(\"do_lower_case:\", do_lower_case)\n",
        "\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab file: b'/tmp/tfhub_modules/3e9209b9f2a53dfa4e6d93250dfceb5e64d73b66/assets/vocab.txt'\n",
            "do_lower_case: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asdN3KjDrNZE"
      },
      "source": [
        "ğŸ‘‰ BERTì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ì‚¬ì „ì´ ìœ„ì— í”„ë¦°íŠ¸ëœ ê²½ë¡œì— txt íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   \n",
        "ğŸ‘‰ ì†Œë¬¸ìí™”ë¥¼ ì§„í–‰í•˜ì—¬ í•™ìŠµí•œ BERTë„ ìˆì§€ë§Œ ë‹¤êµ­ì–´ ëª¨ë¸ì€ ì†Œë¬¸ìí™”ë¥¼ í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— do_lower_case=Falseì¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42k2GhFMvwan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "de163e9c-a625-4752-c158-a995aa83a7b3"
      },
      "source": [
        "# vocab ì‚¬ì „ í™•ì¸í•˜ê¸°\n",
        "\n",
        "print(\"ë‹¨ì–´ì‚¬ì „ì— ìˆëŠ” í† í° ê°œìˆ˜:\", len(tokenizer.vocab))\n",
        "print(\"ì˜ˆì‹œ:\", list(tokenizer.vocab.keys())[:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ë‹¨ì–´ì‚¬ì „ì— ìˆëŠ” í† í° ê°œìˆ˜: 119547\n",
            "ì˜ˆì‹œ: ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]', '[unused50]', '[unused51]', '[unused52]', '[unused53]', '[unused54]', '[unused55]', '[unused56]', '[unused57]', '[unused58]', '[unused59]', '[unused60]', '[unused61]', '[unused62]', '[unused63]', '[unused64]', '[unused65]', '[unused66]', '[unused67]', '[unused68]', '[unused69]', '[unused70]', '[unused71]', '[unused72]', '[unused73]', '[unused74]', '[unused75]', '[unused76]', '[unused77]', '[unused78]', '[unused79]', '[unused80]', '[unused81]', '[unused82]', '[unused83]', '[unused84]', '[unused85]', '[unused86]', '[unused87]', '[unused88]', '[unused89]', '[unused90]', '[unused91]', '[unused92]', '[unused93]', '[unused94]', '[unused95]', '[unused96]', '[unused97]', '[unused98]', '[unused99]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '<S>', '<T>', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', 'Â¡', 'Â¢', 'Â£', 'Â¥', 'Â¦', 'Â§', 'Â¨', 'Â©', 'Âª', 'Â«', 'Â¬', 'Â®', 'Â°', 'Â±', 'Â²', 'Â³', 'Âµ', 'Â¶', 'Â·', 'Â¹', 'Âº', 'Â»', 'Â¼', 'Â½', 'Â¾', 'Â¿', 'Ã€', 'Ã', 'Ã‚', 'Ãƒ', 'Ã„', 'Ã…', 'Ã†', 'Ã‡', 'Ãˆ', 'Ã‰', 'ÃŠ', 'Ã‹', 'ÃŒ', 'Ã', 'Ã', 'Ã', 'Ã‘', 'Ã’', 'Ã“', 'Ã”', 'Ã•', 'Ã–', 'Ã—', 'Ã˜', 'Ãš', 'Ãœ', 'Ã', 'Ã', 'ÃŸ', 'Ã ', 'Ã¡', 'Ã¢', 'Ã£', 'Ã¤', 'Ã¥', 'Ã¦', 'Ã§', 'Ã¨', 'Ã©', 'Ãª', 'Ã«', 'Ã¬', 'Ã­', 'Ã®', 'Ã¯', 'Ã°', 'Ã±', 'Ã²', 'Ã³', 'Ã´', 'Ãµ', 'Ã¶', 'Ã·', 'Ã¸', 'Ã¹', 'Ãº', 'Ã»', 'Ã¼', 'Ã½', 'Ã¾', 'Ã¿', 'Ä€', 'Ä', 'Ä‚', 'Äƒ', 'Ä„', 'Ä…', 'Ä†', 'Ä‡', 'ÄŒ', 'Ä', 'Ä', 'Ä', 'Ä', 'Ä‘']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sp8PwK7rpJR"
      },
      "source": [
        "ğŸ‘‰ ì´ 119,547ê°œì˜ í† í°ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   \n",
        "ğŸ‘‰ [PAD] í† í°ë¶€í„° ì‹œì‘í•´ unusedë¡œ ì˜ˆì•½ëœ ìë¦¬ê°€ ìˆê³ , ì˜ì–´, ëŸ¬ì‹œì•„ì–´(?) ë“± ë‹¤ì–‘í•œ ì–¸ì–´ì˜ í† í°ë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   \n",
        "ğŸ‘‰ í•œêµ­ì–´ë§Œì„ ìœ„í•œ ëª¨ë¸ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—, í•œêµ­ì–´ë§Œìœ¼ë¡œ ì‚¬ì „í•™ìŠµí•œ BERTì— ë¹„í•´ì„œëŠ” ì„±ëŠ¥ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤ ã… .ã… "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCkpLouDmAJr"
      },
      "source": [
        "\"\"\" í˜•íƒœì†Œ ë¶„ì„ í•¨ìˆ˜ \"\"\"\n",
        "from konlpy.tag import Okt\n",
        "okt=Okt()\n",
        "\n",
        "def tokenize(lines):\n",
        "  return okt.morphs(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o089Zp2-Ijp"
      },
      "source": [
        "ğŸ‘‰ 1~2ì¼ì°¨ ì‹¤ìŠµì—ì„œ ì €í¬ëŠ” Komoran í˜•íƒœì†Œë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.    \n",
        "í•˜ì§€ë§Œ Komoranì€ ì›í˜•ì„ ë³µì›í•˜ì—¬ í˜•íƒœì†Œë¥¼ ë¶„ì„í•˜ëŠ” ì•„ì´ì˜€ìŠµë‹ˆë‹¤.   \n",
        "\n",
        "ğŸ‘‰ Sub-tokenizingì„ ìœ„í•´ì„œëŠ” ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ìª¼ê°œê¸°ë§Œ í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, okt ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxT95BwawwXU"
      },
      "source": [
        "#### Step 2. í˜•íƒœì†Œ ë¶„ì„ + Subtokenization ì‹¤í–‰í•˜ê¸°\n",
        "- tokenizer.tokenize ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i20ZPyEMQJYl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "75e129b7-e07e-41ef-b264-018364924f8e"
      },
      "source": [
        "sentence = \"ë²„íŠ¸ë¡œ í† í¬ë‚˜ì´ì¦ˆí•˜ëŠ” ì˜ˆì œ\"\n",
        "\n",
        "# basic_tokenizerë¡œ ë¬¸ì¥ ìª¼ê°œê¸°\n",
        "tokenized_sentence = tokenize(sentence)\n",
        "print(tokenized_sentence)\n",
        "\n",
        "# BPEë¡œ ë¬¸ì¥ ìª¼ê°œê¸°\n",
        "sub_tokens = tokenizer.tokenize(\" \".join(tokenized_sentence))\n",
        "print(sub_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ë²„íŠ¸', 'ë¡œ', 'í† í¬', 'ë‚˜', 'ì´ì¦ˆ', 'í•˜', 'ëŠ”', 'ì˜ˆì œ']\n",
            "['ë²„', '##íŠ¸', 'ë¡œ', 'í† ', '##í¬', 'ë‚˜', 'ì´', '##ì¦ˆ', 'í•˜', 'ëŠ”', 'ì˜ˆ', '##ì œ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OZPX2p9uzjd"
      },
      "source": [
        "ğŸ‘‰ tokenizer.tokenize í•¨ìˆ˜ë¥¼ í†µí•´ í˜•íƒœì†Œ ë¶„ì„ëœ ë¬¸ì¥ì„ WordPiece ë‹¨ìœ„ë¡œ ìª¼ê°­ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHWQn07B4Oq5"
      },
      "source": [
        "ğŸ™†â€â™€ï¸ ì›í•˜ëŠ” ìì—°ì–´ ë¬¸ì¥ì„ BERT tokenizerë¡œ ìª¼ê°œê³  ê²°ê³¼ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ghjyqZN4M8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "87f4dfd6-523e-49d6-c9a8-8adfee665129"
      },
      "source": [
        "sentence = \"í–„ë²„ê±°ëŠ” ì—­ì‹œ ë²„ê±°í‚¹\"\n",
        "\n",
        "# basic_tokenizerë¡œ ë¬¸ì¥ ìª¼ê°œê¸°\n",
        "tokenized_sentence = tokenize(sentence)\n",
        "print(tokenized_sentence)\n",
        "\n",
        "# Sub-tokenìœ¼ë¡œ ìª¼ê°œê¸°\n",
        "print(tokenizer.tokenize(\" \".join(tokenized_sentence)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['í–„ë²„ê±°', 'ëŠ”', 'ì—­ì‹œ', 'ë²„ê±°í‚¹']\n",
            "['í–„', '##ë²„', '##ê±°', 'ëŠ”', 'ì—­ì‹œ', 'ë²„', '##ê±°', '##í‚¹']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPOwbFPOwzIU"
      },
      "source": [
        "#### Step 3. BPE í† í°ì„ ëª¨ë¸ ì¸í’‹ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°\n",
        "- tokenizer.convert_tokens_to_idsë¥¼ ì‚¬ìš©í•˜ë©´ Subtokenì„ ì¸ë±ìŠ¤ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
        "- ìš°ë¦¬ê°€ ì½”ë”©í•´ì„œ ì‚¬ìš©í–ˆë˜ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGhw8GKGQJUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "37874a21-70df-48e0-99cb-c8a06ced717e"
      },
      "source": [
        "# ëª¨ë¸ ì¸í’‹ ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ê¸°\n",
        "print(sub_tokens)\n",
        "input_ids = tokenizer.convert_tokens_to_ids(sub_tokens)\n",
        "print(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ë²„', '##íŠ¸', 'ë¡œ', 'í† ', '##í¬', 'ë‚˜', 'ì´', '##ì¦ˆ', 'í•˜', 'ëŠ”', 'ì˜ˆ', '##ì œ']\n",
            "[9336, 15184, 9202, 9873, 20308, 8982, 9638, 24891, 9952, 9043, 9576, 17730]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQFbO9yy4MAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62c5b633-ec52-4e84-997f-1c67765518eb"
      },
      "source": [
        "# ì¸í’‹ ì¸ë±ìŠ¤ë¥¼ í† í°ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
        "reversed_token = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "print(reversed_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ë²„', '##íŠ¸', 'ë¡œ', 'í† ', '##í¬', 'ë‚˜', 'ì´', '##ì¦ˆ', 'í•˜', 'ëŠ”', 'ì˜ˆ', '##ì œ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwdOTe6ovOgE"
      },
      "source": [
        "## #4. BERT vocab ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•˜ê¸°\n",
        "BERTì—ëŠ” ë¬´ë ¤ 99ê°œì˜ unused í† í° ìë¦¬ê°€ ì˜ˆì•½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   \n",
        "ì´ ìë¦¬ë¥¼ ì–´ë–¤ ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTr0ZzG-vcoy"
      },
      "source": [
        "ë¨¼ì € ì›ë˜ ë‹¨ì–´ì‚¬ì „ text íŒŒì¼ì„ ì—´ì–´ org_vocabsë¼ëŠ” ë¦¬ìŠ¤íŠ¸ì— ì½ì–´ì˜¤ê² ìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRf8Y8qiGlUX"
      },
      "source": [
        "## ì›ë˜ ë‹¨ì–´ ì‚¬ì „ í™•ì¸í•˜ê¸°\n",
        "\n",
        "with open(vocab_file) as f:\n",
        "  org_vocabs = [s.strip() for s in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJpoq_a3GlOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "db5080d4-91b6-4d34-b2ba-bd8da1bc85c5"
      },
      "source": [
        "print(\"# vocabs:\", len(org_vocabs))\n",
        "print(org_vocabs[:101])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# vocabs: 119547\n",
            "['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]', '[unused50]', '[unused51]', '[unused52]', '[unused53]', '[unused54]', '[unused55]', '[unused56]', '[unused57]', '[unused58]', '[unused59]', '[unused60]', '[unused61]', '[unused62]', '[unused63]', '[unused64]', '[unused65]', '[unused66]', '[unused67]', '[unused68]', '[unused69]', '[unused70]', '[unused71]', '[unused72]', '[unused73]', '[unused74]', '[unused75]', '[unused76]', '[unused77]', '[unused78]', '[unused79]', '[unused80]', '[unused81]', '[unused82]', '[unused83]', '[unused84]', '[unused85]', '[unused86]', '[unused87]', '[unused88]', '[unused89]', '[unused90]', '[unused91]', '[unused92]', '[unused93]', '[unused94]', '[unused95]', '[unused96]', '[unused97]', '[unused98]', '[unused99]', '[UNK]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmRe37uGOxKX"
      },
      "source": [
        "ì´ë²ˆ í”„ë¡œì íŠ¸ë¡œ LG CNS ë¸”ë¡œê·¸ ëŒ“ê¸€ì— ëŒ€í•œ ê°ì„± ëª¨ë‹ˆí„°ë§ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ë ¤ê³  í•©ë‹ˆë‹¤.   \n",
        "ìì‚¬ì˜ ë¸”ë¡œê·¸ì´ë‹¤ë³´ë‹ˆ \\<CNS>, <ì—˜ì§€> ê°™ì€ ë‹¨ì–´ë“¤ì´ ë§ì´ ë³´ì…ë‹ˆë‹¤.   \n",
        "\n",
        "ì €í¬ íšŒì‚¬ ì´ë¦„ì´ ë“¤ì–´ê°„ ë§Œí¼ ì´ í† í°ë“¤ì€ subwordë¡œ í† í¬ë‚˜ì´ì¦ˆë˜ëŠ” ëŒ€ì‹  í•˜ë‚˜ì˜ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê³  ì‹¶ì€ë°ìš”,   \n",
        "ë¨¼ì € ì›ë˜ BERT ë‹¨ì–´ì‚¬ì „ì— ì´ ë‹¨ì–´ë“¤ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5g5Gu7YGlLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4913959d-a0c0-4adc-d074-92bad0f2b2d7"
      },
      "source": [
        "print(\"CNS\" in org_vocabs)\n",
        "print(\"ì—˜ì§€\" in org_vocabs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A7hHqZawGUd"
      },
      "source": [
        "ğŸ‘‰ ì´ëŸ°, êµ¬ê¸€ì´ ê³µê°œí•œ BERTì˜ ë‹¨ì–´ì‚¬ì „ì—ëŠ” ì´ í† í°ë“¤ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.   \n",
        "ğŸ‘‰ ê·¸ë ‡ë‹¤ë©´ ì§€ê¸ˆì€ ì´ëŸ° í† í°ë“¤ì´ í¬í•¨ëœ ë¬¸ì¥ì€ ì–´ë–»ê²Œ íŒŒì‹±ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGRwcYo5IIU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "470449e3-cf8b-4d5e-a61f-f8982d363a81"
      },
      "source": [
        "tokenized = tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš” ì—˜ì§€ CNS ì„ìŠ¹ì˜ ì„ ì„ ì—°êµ¬ì›ì…ë‹ˆë‹¤.\")\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
        "print(input_ids)\n",
        "reversed_token = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "print(reversed_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9521, 118741, 35506, 24982, 48549, 9562, 12508, 73067, 10731, 9644, 48210, 30858, 9428, 36240, 91785, 14279, 58303, 48345, 119]\n",
            "['ì•ˆ', '##ë…•', '##í•˜', '##ì„¸', '##ìš”', 'ì—˜', '##ì§€', 'CN', '##S', 'ì„', '##ìŠ¹', '##ì˜', 'ì„ ', '##ì„', 'ì—°êµ¬', '##ì›', '##ì…', '##ë‹ˆë‹¤', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbQe1R5bwX-T"
      },
      "source": [
        "ğŸ‘‰ Vocabì— ë‹¨ì–´ê°€ ì—†ë‹¤ë³´ë‹ˆ CNSëŠ” CN ##S , ì—˜ì§€ëŠ” ì—˜ ##ì§€ ë¡œ ì°¢ì–´ì ¸ì„œ í† í¬ë‚˜ì´ì§•ë˜ê³  ìˆìŠµë‹ˆë‹¤. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fP7sRx1wx2Y"
      },
      "source": [
        "ì´ëŸ° í˜„ìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´, ë¶„ë¦¬ë˜ì§€ ì•Šê³  ë¶„ì„ë˜ì—ˆìœ¼ë©´ í•˜ëŠ” í† í°ë“¤ì„ ì¶”ê°€í•´ ìƒˆë¡œìš´ ë‹¨ì–´ì‚¬ì „ì„ ë§Œë“¤ê³    \n",
        "ì´ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxRXN9KpJHgt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02231895-0690-4f10-f955-47f8c84d5ded"
      },
      "source": [
        "never_split = [\"ì—˜ì§€\", \"CNS\"]\n",
        "\n",
        "## ì¶”ê°€í•œ never_split ë‹¨ì–´ë¥¼ ë°˜ì˜í•´ ìƒˆë¡œìš´ ì‚¬ì „ì„ ë§Œë“¤ì–´ì£¼ê¸°\n",
        "new_vocabs = org_vocabs.copy()\n",
        "idx = 1\n",
        "for tok in never_split:\n",
        "  if tok not in org_vocabs: # (ì•ˆì „ì¥ì¹˜ 1) ì›ë˜ vocabì— ì—†ìœ¼ë©´\n",
        "    if \"unused\" in new_vocabs[idx]: # (ì•ˆì „ì¥ì¹˜ 2) [unused] í† í° ìë¦¬ì´ë©´\n",
        "      new_vocabs[idx] = tok\n",
        "      print(\"{} -> {}\".format(org_vocabs[idx], new_vocabs[idx]))\n",
        "      idx += 1\n",
        "    else:\n",
        "      \"Cannot Allocate New Token Anymore\"\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[unused1] -> ì—˜ì§€\n",
            "[unused2] -> CNS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nbDGdKaw9-I"
      },
      "source": [
        "ğŸ‘‰ new_vocabsì—ëŠ” never_splitìœ¼ë¡œ ì •í•œ í† í°ë“¤ì„ í¬í•¨í•œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ê°€ ì €ì¥ë©ë‹ˆë‹¤. \n",
        "\n",
        "ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ëŠ” ê³¼ì •ì—ì„œëŠ” ë‘ ê°€ì§€ ì•ˆì „ì¥ì¹˜ë¥¼ ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤. \n",
        "1. ì›ë˜ vocabì— ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€í•˜ê¸° -> ë‹¨ì–´ì‚¬ì „ì—ëŠ” ì¤‘ë³µì´ ìˆìœ¼ë©´ ì•ˆ ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.   \n",
        "2. [unused #] í† í°ì¼ ë•Œë§Œ ëŒ€ì²´í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqGmm2aGqMyj"
      },
      "source": [
        "## ìƒˆ ë‹¨ì–´ì‚¬ì „ ì €ì¥\n",
        "new_vocab_file = \"/content/new_vocab.txt\"\n",
        "\n",
        "with open(new_vocab_file, \"w\") as f:\n",
        "  f.write(\"\\n\".join(new_vocabs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-4vcsdOxz6T"
      },
      "source": [
        "ì´ì œ ìƒˆë¡œ ì €ì¥í•œ ë‹¨ì–´ì‚¬ì „ì„ ì‚¬ìš©í•´ new_tokenizerë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë‹¤ì‹œ í•œ ë²ˆ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeYyFCbcqSm0"
      },
      "source": [
        "## ìƒˆë¡œìš´ ì‚¬ì „ì„ ì´ìš©í•´ ë¡œë”©\n",
        "\n",
        "new_tokenizer = bert_tokenization.FullTokenizer(new_vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDvr0xwVJQs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "0ce30034-e0c1-493f-d4f0-2e8ea5ccae70"
      },
      "source": [
        "tokenized = new_tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš” ì—˜ì§€ CNS ì„ìŠ¹ì˜ ì„ ì„ ì—°êµ¬ì›ì…ë‹ˆë‹¤.\")\n",
        "print(tokenized)\n",
        "input_ids = new_tokenizer.convert_tokens_to_ids(tokenized)\n",
        "print(input_ids)\n",
        "reversed_token = new_tokenizer.convert_ids_to_tokens(input_ids)\n",
        "print(reversed_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ì•ˆ', '##ë…•', '##í•˜', '##ì„¸', '##ìš”', 'ì—˜ì§€', 'CNS', 'ì„', '##ìŠ¹', '##ì˜', 'ì„ ', '##ì„', 'ì—°êµ¬', '##ì›', '##ì…', '##ë‹ˆë‹¤', '.']\n",
            "[9521, 118741, 35506, 24982, 48549, 1, 2, 9644, 48210, 30858, 9428, 36240, 91785, 14279, 58303, 48345, 119]\n",
            "['ì•ˆ', '##ë…•', '##í•˜', '##ì„¸', '##ìš”', 'ì—˜ì§€', 'CNS', 'ì„', '##ìŠ¹', '##ì˜', 'ì„ ', '##ì„', 'ì—°êµ¬', '##ì›', '##ì…', '##ë‹ˆë‹¤', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYEN2AfLyWMA"
      },
      "source": [
        "ğŸ‘‰ í† í°ì„ ì¶”ê°€í–ˆê¸° ë•Œë¬¸ì— ì´ë²ˆì—ëŠ” \"ì—˜ì§€\"ì™€ \"CNS\"ê°€ ìª¼ê°œì§€ì§€ ì•Šê³  í† í¬ë‚˜ì´ì§•ë˜ì—ˆìŠµë‹ˆë‹¤.   \n",
        "ğŸ‘‰ ë¸”ë¡œê·¸ ëŒ“ê¸€ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ BERTëŠ” fine-tuningì„ í†µí•´ ìƒˆë¡œ ì¶”ê°€ëœ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ í•™ìŠµí•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKyRlIK8ynsQ"
      },
      "source": [
        "## #5. DAILY MISSION   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt693N4gzFSL"
      },
      "source": [
        "<font color=\"red\">MISSION: BERT í† í¬ë‚˜ì´ì§• & ì¸ë±ì‹± í•´ë³´ê¸° </font>\n",
        "\n",
        "BERTë¥¼ ì‚¬ìš©í•´ ê°ì„±ë¶„ì„ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ê³ ì í•©ë‹ˆë‹¤.    \n",
        "ê°ì„±ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ì¸í’‹ ë¬¸ì¥ì„ <b>[CLS] ì¸í’‹ë¬¸ì¥ [SEP]</b>ì˜ í˜•íƒœë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. \n",
        "\n",
        "ì¸í’‹ ë¬¸ì¥ìœ¼ë¡œ \"BERT ì•Œê³  ë³´ë‹ˆ ì™„ì „ ì‰½ë„¤\"ë¼ëŠ” ë¬¸ì¥ì´ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤.   \n",
        "\n",
        "1. í˜•íƒœì†Œë¶„ì„ê³¼ BERT í† í¬ë‚˜ì´ì§•ì„ ì§„í–‰í•´ ìœ„ì˜ ë¬¸ì¥ì„ subtokenizeí•˜ê³ ,    \n",
        "[CLS] ì¸í’‹ë¬¸ì¥ í† í°ë“¤ [SEP] ì˜ í˜•íƒœë¡œ ë§Œë“œì„¸ìš”. \n",
        "2. í† í¬ë‚˜ì´ì¦ˆëœ ë¬¸ì¥ì„ BERTì˜ ë‹¨ì–´ì‚¬ì „ì„ ì‚¬ìš©í•´ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWWDkiFe4CGp"
      },
      "source": [
        "<ì‹¤í–‰ ê²°ê³¼ëŠ” ì˜ˆì‹œ>   \n",
        "- í˜•íƒœì†Œ ë¶„ì„ í›„ -> ['BERT', 'ì•Œ', 'ê³ ', 'ë³´ë‹ˆ', 'ì™„ì „', 'ì‰½ë„¤']\n",
        "- Sub-tokenizing í›„ -> ['BE', '##RT', 'ì•Œ', 'ê³ ', 'ë³´', '##ë‹ˆ', 'ì™„', '##ì „', 'ì‰½', '##ë„¤']\n",
        "- BERT ì¸í’‹ í˜•íƒœ ë³€í™˜ -> ['[CLS]', 'BE', '##RT', 'ì•Œ', 'ê³ ', 'ë³´', '##ë‹ˆ', 'ì™„', '##ì „', 'ì‰½', '##ë„¤', '[SEP]']\n",
        "- BERT ì •ìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜ -> [101, 46291, 46935, 9524, 8888, 9356, 25503, 9591, 16617, 9471, 77884, 102]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775USuqpItyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "afa4ba50-405b-4a3a-a5a0-193f745b7bab"
      },
      "source": [
        "\"\"\" Your Code Here \"\"\"\n",
        "\n",
        "sentence = \"BERT ì•Œê³  ë³´ë‹ˆ ì™„ì „ ì‰½ë„¤\"\n",
        " \n",
        "tokenized_sentence = tokenize(sentence)\n",
        "print(tokenized_sentence)\n",
        " \n",
        "# Sub-tokenìœ¼ë¡œ ìª¼ê°œê¸°\n",
        "sub_tokenized_sent = tokenizer.tokenize(\" \".join(tokenized_sentence))\n",
        "print(sub_tokenized_sent)\n",
        " \n",
        "# [CLS] Subtokens [SEP] í˜•íƒœë¡œ ë§Œë“¤ê¸°\n",
        "sub_tokenized_sent = [\"[CLS]\"] + sub_tokenized_sent + [\"[SEP]\"]\n",
        "print(sub_tokenized_sent)\n",
        " \n",
        "# ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ê¸°\n",
        "input_ids = tokenizer.convert_tokens_to_ids(sub_tokenized_sent)\n",
        "print(input_ids)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BERT', 'ì•Œ', 'ê³ ', 'ë³´ë‹ˆ', 'ì™„ì „', 'ì‰½ë„¤']\n",
            "['BE', '##RT', 'ì•Œ', 'ê³ ', 'ë³´', '##ë‹ˆ', 'ì™„', '##ì „', 'ì‰½', '##ë„¤']\n",
            "['[CLS]', 'BE', '##RT', 'ì•Œ', 'ê³ ', 'ë³´', '##ë‹ˆ', 'ì™„', '##ì „', 'ì‰½', '##ë„¤', '[SEP]']\n",
            "[101, 46291, 46935, 9524, 8888, 9356, 25503, 9591, 16617, 9471, 77884, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}